{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "plt = mpl.pyplot\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.autolimit_mode'] = 'round_numbers'\n",
    "mpl.rcParams['axes.xmargin'] = 0\n",
    "mpl.rcParams['axes.ymargin'] = 0\n",
    "import numpy as np\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_features, training_labels, validation_features, validation_labels = \\\n",
    "#     utils.get_training_data(0.2, onehot=False, standardize=False)\n",
    "# print(training_features.shape, training_labels.shape,\n",
    "#      validation_features.shape, validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-Idf transform\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tfidf = TfidfTransformer()\n",
    "# training_features = tfidf.fit_transform(training_features)\n",
    "# validation_features = tfidf.transform(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "def create_model(dense=(160,), activation='sigmoid', dropout=0.7):\n",
    "    model = Sequential()\n",
    "    for d in dense:\n",
    "        model.add(Dense(d, input_shape=(1000,)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activation))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "class KerasClassifierMod(KerasClassifier):\n",
    "    def fit(self, x, y, sample_weight, **kwargs):\n",
    "        return super().fit(x, y, sample_weight=sample_weight, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = KerasClassifierMod(build_fn=create_model, epochs=1, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "n_estimators = 50\n",
    "learning_rate = 0.1\n",
    "ada_nn = AdaBoostClassifier(base_estimator=nn, n_estimators=n_estimators, \n",
    "                        learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ada_nn.fit(training_features, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "def plot_ada_hist(ada, title):\n",
    "    ada_acc = np.zeros((n_estimators,))\n",
    "    for i, pred_labels in enumerate(ada.staged_predict(validation_features)):\n",
    "        ada_acc[i] = zero_one_loss(pred_labels, validation_labels)\n",
    "\n",
    "    ada_acc_train = np.zeros((n_estimators,))\n",
    "    for i, pred_labels in enumerate(ada.staged_predict(training_features)):\n",
    "        ada_acc_train[i] = zero_one_loss(pred_labels, training_labels)\n",
    "\n",
    "    plt.figure(dpi=300)\n",
    "    plt.plot(np.arange(n_estimators) + 1, ada_acc, label='AdaBoost Test Loss')\n",
    "    plt.plot(np.arange(n_estimators) + 1, ada_acc_train, label='AdaBoost Train Loss')\n",
    "    plt.semilogy()\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_ada_hist(ada_nn, 'AdaBoost with neural network\\nfinal accuracy %.4f'\n",
    "#              %ada_nn.score(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1000) (20000,)\n"
     ]
    }
   ],
   "source": [
    "# Now the final training\n",
    "training_features1, training_labels1, _, _ = \\\n",
    "    utils.get_training_data(0, onehot=False, standardize=False)\n",
    "print(training_features1.shape, training_labels1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "test_features1 = utils.get_test_data(standardize=False)\n",
    "print(test_features1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-Idf transform\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "training_features1 = tfidf.fit_transform(training_features1)\n",
    "test_features1 = tfidf.transform(test_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 14s 705us/step - loss: 3.0377e-05 - acc: 0.6692\n",
      "20000/20000 [==============================] - 1s 62us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 278us/step - loss: 3.0661e-05 - acc: 0.6665\n",
      "20000/20000 [==============================] - 1s 64us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 275us/step - loss: 3.1179e-05 - acc: 0.6623\n",
      "20000/20000 [==============================] - 1s 66us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 280us/step - loss: 3.1025e-05 - acc: 0.6724\n",
      "20000/20000 [==============================] - 1s 67us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 284us/step - loss: 3.1333e-05 - acc: 0.6647\n",
      "20000/20000 [==============================] - 1s 69us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 290us/step - loss: 3.1380e-05 - acc: 0.6624\n",
      "20000/20000 [==============================] - 1s 74us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 292us/step - loss: 3.1572e-05 - acc: 0.6640\n",
      "20000/20000 [==============================] - 2s 78us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 303us/step - loss: 3.1564e-05 - acc: 0.6662\n",
      "20000/20000 [==============================] - 2s 76us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 301us/step - loss: 3.1634e-05 - acc: 0.6682\n",
      "20000/20000 [==============================] - 2s 82us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 7s 351us/step - loss: 3.2049e-05 - acc: 0.6610\n",
      "20000/20000 [==============================] - 2s 88us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 309us/step - loss: 3.2190e-05 - acc: 0.6601\n",
      "20000/20000 [==============================] - 2s 83us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 7s 332us/step - loss: 3.2279e-05 - acc: 0.6634\n",
      "20000/20000 [==============================] - 2s 87us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 318us/step - loss: 3.2642e-05 - acc: 0.6553\n",
      "20000/20000 [==============================] - 2s 89us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 6s 320us/step - loss: 3.2536e-05 - acc: 0.6588\n",
      "20000/20000 [==============================] - 2s 89us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 7s 327us/step - loss: 3.2773e-05 - acc: 0.6563\n",
      "20000/20000 [==============================] - 2s 92us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 7s 334us/step - loss: 3.2972e-05 - acc: 0.6553\n",
      "20000/20000 [==============================] - 2s 96us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 7s 339us/step - loss: 3.3041e-05 - acc: 0.6575\n",
      "20000/20000 [==============================] - 2s 97us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 7s 344us/step - loss: 3.3085e-05 - acc: 0.6482\n",
      "20000/20000 [==============================] - 2s 100us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 7s 346us/step - loss: 3.3628e-05 - acc: 0.6451\n",
      "20000/20000 [==============================] - 2s 106us/step\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 7s 355us/step - loss: 3.3455e-05 - acc: 0.6472\n",
      "20000/20000 [==============================] - 2s 107us/step\n"
     ]
    }
   ],
   "source": [
    "nn = KerasClassifierMod(build_fn=create_model, epochs=1, batch_size=32, verbose=1)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "n_estimators = 80\n",
    "learning_rate = 0.05\n",
    "ada_nn1 = AdaBoostClassifier(base_estimator=nn, n_estimators=n_estimators, \n",
    "                        learning_rate=learning_rate)\n",
    "ada_nn1.fit(training_features1, training_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels1 = ada_nn1.predict(test_features1)\n",
    "utils.save_prediction(test_labels1, 'data/test_labels_ada_nn.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
