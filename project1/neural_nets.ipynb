{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, training_labels, validation_features, validation_labels = \\\n",
    "    utils.get_training_data(onehot=True, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 100,302\n",
      "Trainable params: 100,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.8247 - acc: 0.6190 - val_loss: 0.4561 - val_acc: 0.7988\n",
      "Epoch 2/30\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.5169 - acc: 0.7507 - val_loss: 0.4083 - val_acc: 0.8288\n",
      "Epoch 3/30\n",
      "14000/14000 [==============================] - 1s 45us/step - loss: 0.4499 - acc: 0.7932 - val_loss: 0.3804 - val_acc: 0.8400\n",
      "Epoch 4/30\n",
      "14000/14000 [==============================] - 1s 46us/step - loss: 0.4081 - acc: 0.8157 - val_loss: 0.3649 - val_acc: 0.8442\n",
      "Epoch 5/30\n",
      "14000/14000 [==============================] - 1s 46us/step - loss: 0.3783 - acc: 0.8378 - val_loss: 0.3573 - val_acc: 0.8450\n",
      "Epoch 6/30\n",
      "14000/14000 [==============================] - 1s 45us/step - loss: 0.3633 - acc: 0.8438 - val_loss: 0.3511 - val_acc: 0.8495\n",
      "Epoch 7/30\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.3467 - acc: 0.8501 - val_loss: 0.3493 - val_acc: 0.8487\n",
      "Epoch 8/30\n",
      "14000/14000 [==============================] - 1s 46us/step - loss: 0.3327 - acc: 0.8568 - val_loss: 0.3466 - val_acc: 0.8518\n",
      "Epoch 9/30\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.3189 - acc: 0.8632 - val_loss: 0.3468 - val_acc: 0.8510\n",
      "Epoch 10/30\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.3178 - acc: 0.8650 - val_loss: 0.3472 - val_acc: 0.8517\n",
      "Epoch 11/30\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.3107 - acc: 0.8661 - val_loss: 0.3482 - val_acc: 0.8515\n",
      "Epoch 12/30\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.3037 - acc: 0.8732 - val_loss: 0.3473 - val_acc: 0.8527\n",
      "Epoch 13/30\n",
      "14000/14000 [==============================] - 1s 45us/step - loss: 0.2929 - acc: 0.8806 - val_loss: 0.3492 - val_acc: 0.8523\n",
      "Epoch 14/30\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.2912 - acc: 0.8786 - val_loss: 0.3490 - val_acc: 0.8522\n",
      "Epoch 15/30\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.2843 - acc: 0.8821 - val_loss: 0.3510 - val_acc: 0.8482\n",
      "Epoch 16/30\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 0.2807 - acc: 0.8837 - val_loss: 0.3518 - val_acc: 0.8522\n",
      "Epoch 17/30\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 0.2734 - acc: 0.8872 - val_loss: 0.3541 - val_acc: 0.8500\n",
      "Epoch 18/30\n",
      "14000/14000 [==============================] - 1s 45us/step - loss: 0.2710 - acc: 0.8873 - val_loss: 0.3543 - val_acc: 0.8508\n",
      "Epoch 19/30\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.2654 - acc: 0.8901 - val_loss: 0.3569 - val_acc: 0.8515\n",
      "Epoch 20/30\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.2613 - acc: 0.8925 - val_loss: 0.3592 - val_acc: 0.8498\n",
      "Epoch 21/30\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.2591 - acc: 0.8950 - val_loss: 0.3600 - val_acc: 0.8503\n",
      "Epoch 22/30\n",
      "14000/14000 [==============================] - 1s 52us/step - loss: 0.2524 - acc: 0.8959 - val_loss: 0.3630 - val_acc: 0.8495\n",
      "Epoch 23/30\n",
      "14000/14000 [==============================] - 1s 46us/step - loss: 0.2539 - acc: 0.8956 - val_loss: 0.3633 - val_acc: 0.8497\n",
      "Epoch 24/30\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.2420 - acc: 0.9038 - val_loss: 0.3656 - val_acc: 0.8487\n",
      "Epoch 25/30\n",
      "14000/14000 [==============================] - 1s 45us/step - loss: 0.2407 - acc: 0.9016 - val_loss: 0.3684 - val_acc: 0.8497\n",
      "Epoch 26/30\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.2377 - acc: 0.9004 - val_loss: 0.3722 - val_acc: 0.8478\n",
      "Epoch 27/30\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.2354 - acc: 0.9044 - val_loss: 0.3739 - val_acc: 0.8477\n",
      "Epoch 28/30\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 0.2285 - acc: 0.9047 - val_loss: 0.3756 - val_acc: 0.8487\n",
      "Epoch 29/30\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.2316 - acc: 0.9069 - val_loss: 0.3760 - val_acc: 0.8487\n",
      "Epoch 30/30\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 0.2279 - acc: 0.9085 - val_loss: 0.3785 - val_acc: 0.8497\n",
      "Model 1 test score: 0.37847813268502556\n",
      "Model 1 test accuracy: 0.8496666666666667\n"
     ]
    }
   ],
   "source": [
    "# Our first 160-unit model\n",
    "model1 = Sequential()\n",
    "\n",
    "# A single fully connected layer with 160 units\n",
    "model1.add(Dense(100, input_shape=(training_features.shape[1],)))\n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "# Drop out 10% of units for regularization\n",
    "model1.add(Dropout(0.80))\n",
    "\n",
    "# Softmax classification layer\n",
    "model1.add(Dense(2))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "## Printing a summary of the layers and weights in your model\n",
    "model1.summary()\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "fit = model1.fit(training_features, training_labels, batch_size=256, epochs=30, verbose=1,\n",
    "                 validation_data=(validation_features, validation_labels))\n",
    "\n",
    "score1 = model1.evaluate(validation_features, validation_labels, verbose=0)\n",
    "print('Model 1 test score:', score1[0])\n",
    "print('Model 1 test accuracy:', score1[1])\n",
    "\n",
    "best_score = score1\n",
    "best_model = model1\n",
    "best_num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 160)               160160    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 60)                9660      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 122       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 169,942\n",
      "Trainable params: 169,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.8269 - acc: 0.5432 - val_loss: 0.6040 - val_acc: 0.7825\n",
      "Epoch 2/30\n",
      "14000/14000 [==============================] - 1s 53us/step - loss: 0.6342 - acc: 0.6446 - val_loss: 0.4996 - val_acc: 0.8150\n",
      "Epoch 3/30\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.5187 - acc: 0.7457 - val_loss: 0.4055 - val_acc: 0.8322\n",
      "Epoch 4/30\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.4540 - acc: 0.7954 - val_loss: 0.3733 - val_acc: 0.8392\n",
      "Epoch 5/30\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.4114 - acc: 0.8185 - val_loss: 0.3585 - val_acc: 0.8450\n",
      "Epoch 6/30\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.3866 - acc: 0.8336 - val_loss: 0.3534 - val_acc: 0.8440\n",
      "Epoch 7/30\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.3710 - acc: 0.8424 - val_loss: 0.3496 - val_acc: 0.8505\n",
      "Epoch 8/30\n",
      "14000/14000 [==============================] - 1s 58us/step - loss: 0.3592 - acc: 0.8479 - val_loss: 0.3490 - val_acc: 0.8485\n",
      "Epoch 9/30\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.3490 - acc: 0.8571 - val_loss: 0.3486 - val_acc: 0.8487\n",
      "Epoch 10/30\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.3433 - acc: 0.8576 - val_loss: 0.3511 - val_acc: 0.8477\n",
      "Epoch 11/30\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.3294 - acc: 0.8624 - val_loss: 0.3502 - val_acc: 0.8517\n",
      "Epoch 12/30\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.3219 - acc: 0.8706 - val_loss: 0.3517 - val_acc: 0.8512\n",
      "Epoch 13/30\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.3160 - acc: 0.8704 - val_loss: 0.3543 - val_acc: 0.8493\n",
      "Epoch 14/30\n",
      "14000/14000 [==============================] - 1s 63us/step - loss: 0.3154 - acc: 0.8744 - val_loss: 0.3529 - val_acc: 0.8512\n",
      "Epoch 15/30\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.3094 - acc: 0.8778 - val_loss: 0.3549 - val_acc: 0.8512\n",
      "Epoch 16/30\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.3019 - acc: 0.8754 - val_loss: 0.3573 - val_acc: 0.8512\n",
      "Epoch 17/30\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.2957 - acc: 0.8804 - val_loss: 0.3604 - val_acc: 0.8532\n",
      "Epoch 18/30\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.2942 - acc: 0.8827 - val_loss: 0.3608 - val_acc: 0.8498\n",
      "Epoch 19/30\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.2946 - acc: 0.8825 - val_loss: 0.3628 - val_acc: 0.8512\n",
      "Epoch 20/30\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.2858 - acc: 0.8836 - val_loss: 0.3639 - val_acc: 0.8507\n",
      "Epoch 21/30\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.2806 - acc: 0.8896 - val_loss: 0.3654 - val_acc: 0.8505\n",
      "Epoch 22/30\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.2806 - acc: 0.8880 - val_loss: 0.3668 - val_acc: 0.8513\n",
      "Epoch 23/30\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.2762 - acc: 0.8909 - val_loss: 0.3702 - val_acc: 0.8505\n",
      "Epoch 24/30\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 0.2722 - acc: 0.8924 - val_loss: 0.3692 - val_acc: 0.8533\n",
      "Epoch 25/30\n",
      "14000/14000 [==============================] - 1s 60us/step - loss: 0.2701 - acc: 0.8943 - val_loss: 0.3738 - val_acc: 0.8517\n",
      "Epoch 26/30\n",
      "14000/14000 [==============================] - 1s 61us/step - loss: 0.2677 - acc: 0.8972 - val_loss: 0.3744 - val_acc: 0.8532\n",
      "Epoch 27/30\n",
      "14000/14000 [==============================] - 1s 59us/step - loss: 0.2641 - acc: 0.8961 - val_loss: 0.3738 - val_acc: 0.8512\n",
      "Epoch 28/30\n",
      "14000/14000 [==============================] - 1s 57us/step - loss: 0.2603 - acc: 0.8973 - val_loss: 0.3773 - val_acc: 0.8507\n",
      "Epoch 29/30\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.2641 - acc: 0.9000 - val_loss: 0.3788 - val_acc: 0.8490\n",
      "Epoch 30/30\n",
      "14000/14000 [==============================] - 1s 62us/step - loss: 0.2536 - acc: 0.9031 - val_loss: 0.3806 - val_acc: 0.8490\n",
      "Model 2 test score: 0.3806348338127136\n",
      "Model 2 test accuracy: 0.849\n"
     ]
    }
   ],
   "source": [
    "# Let's crank up the layers\n",
    "model2 = Sequential()\n",
    "\n",
    "# The first fully connected layer with 160 units\n",
    "model2.add(Dense(160, input_shape=(training_features.shape[1],)))\n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "# Drop out 30% of units for regularization\n",
    "model2.add(Dropout(0.75))\n",
    "\n",
    "# A second fully connected layer with 60 units\n",
    "model2.add(Dense(60, input_shape=(training_features.shape[1],)))\n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "# Drop out 10% of units for regularization\n",
    "model2.add(Dropout(0.75))\n",
    "\n",
    "# Softmax classification layer\n",
    "model2.add(Dense(2))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "## Printing a summary of the layers and weights in your model\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "fit = model2.fit(training_features, training_labels, batch_size=256, epochs=30, verbose=1,\n",
    "                 validation_data=(validation_features, validation_labels))\n",
    "\n",
    "score2 = model2.evaluate(validation_features, validation_labels, verbose=0)\n",
    "print('Model 2 test score:', score2[0])\n",
    "print('Model 2 test accuracy:', score2[1])\n",
    "\n",
    "if score2 > best_score:\n",
    "    best_score = score2\n",
    "    best_model = model2\n",
    "    best_num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 140)               140140    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 140)               560       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 60)                8460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 25)                1525      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 25)                100       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 52        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 151,077\n",
      "Trainable params: 150,627\n",
      "Non-trainable params: 450\n",
      "_________________________________________________________________\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "14000/14000 [==============================] - 1s 94us/step - loss: 0.8202 - acc: 0.5115 - val_loss: 0.6727 - val_acc: 0.7552\n",
      "Epoch 2/50\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.7729 - acc: 0.5168 - val_loss: 0.6429 - val_acc: 0.7880\n",
      "Epoch 3/50\n",
      "14000/14000 [==============================] - 1s 75us/step - loss: 0.7213 - acc: 0.5453 - val_loss: 0.5853 - val_acc: 0.8160\n",
      "Epoch 4/50\n",
      "14000/14000 [==============================] - 1s 81us/step - loss: 0.6617 - acc: 0.6088 - val_loss: 0.5152 - val_acc: 0.8335\n",
      "Epoch 5/50\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.6058 - acc: 0.6694 - val_loss: 0.4566 - val_acc: 0.8418\n",
      "Epoch 6/50\n",
      "14000/14000 [==============================] - 1s 74us/step - loss: 0.5635 - acc: 0.7107 - val_loss: 0.4140 - val_acc: 0.8480\n",
      "Epoch 7/50\n",
      "14000/14000 [==============================] - 1s 74us/step - loss: 0.5389 - acc: 0.7357 - val_loss: 0.3940 - val_acc: 0.8510\n",
      "Epoch 8/50\n",
      "14000/14000 [==============================] - 1s 75us/step - loss: 0.5071 - acc: 0.7601 - val_loss: 0.3770 - val_acc: 0.8503\n",
      "Epoch 9/50\n",
      "14000/14000 [==============================] - 1s 71us/step - loss: 0.4895 - acc: 0.7728 - val_loss: 0.3692 - val_acc: 0.8525\n",
      "Epoch 10/50\n",
      "14000/14000 [==============================] - 1s 74us/step - loss: 0.4774 - acc: 0.7804 - val_loss: 0.3638 - val_acc: 0.8498\n",
      "Epoch 11/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.4642 - acc: 0.7892 - val_loss: 0.3617 - val_acc: 0.8490\n",
      "Epoch 12/50\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.4533 - acc: 0.7992 - val_loss: 0.3589 - val_acc: 0.8505\n",
      "Epoch 13/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.4465 - acc: 0.8011 - val_loss: 0.3591 - val_acc: 0.8473\n",
      "Epoch 14/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.4333 - acc: 0.8143 - val_loss: 0.3580 - val_acc: 0.8475\n",
      "Epoch 15/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.4319 - acc: 0.8144 - val_loss: 0.3574 - val_acc: 0.8507\n",
      "Epoch 16/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.4253 - acc: 0.8191 - val_loss: 0.3572 - val_acc: 0.8480\n",
      "Epoch 17/50\n",
      "14000/14000 [==============================] - 1s 69us/step - loss: 0.4237 - acc: 0.8169 - val_loss: 0.3573 - val_acc: 0.8488\n",
      "Epoch 18/50\n",
      "14000/14000 [==============================] - 1s 74us/step - loss: 0.4105 - acc: 0.8270 - val_loss: 0.3583 - val_acc: 0.8487\n",
      "Epoch 19/50\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.4134 - acc: 0.8307 - val_loss: 0.3593 - val_acc: 0.8490\n",
      "Epoch 20/50\n",
      "14000/14000 [==============================] - 1s 72us/step - loss: 0.4087 - acc: 0.8309 - val_loss: 0.3608 - val_acc: 0.8463\n",
      "Epoch 21/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.4052 - acc: 0.8309 - val_loss: 0.3603 - val_acc: 0.8457\n",
      "Epoch 22/50\n",
      "14000/14000 [==============================] - 1s 70us/step - loss: 0.3977 - acc: 0.8399 - val_loss: 0.3622 - val_acc: 0.8457\n",
      "Epoch 23/50\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.3886 - acc: 0.8426 - val_loss: 0.3622 - val_acc: 0.8463\n",
      "Epoch 24/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.3951 - acc: 0.8392 - val_loss: 0.3637 - val_acc: 0.8463\n",
      "Epoch 25/50\n",
      "14000/14000 [==============================] - 1s 70us/step - loss: 0.3928 - acc: 0.8416 - val_loss: 0.3633 - val_acc: 0.8460\n",
      "Epoch 26/50\n",
      "14000/14000 [==============================] - 1s 73us/step - loss: 0.3849 - acc: 0.8436 - val_loss: 0.3638 - val_acc: 0.8468\n",
      "Epoch 27/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.3913 - acc: 0.8400 - val_loss: 0.3634 - val_acc: 0.8450\n",
      "Epoch 28/50\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.3812 - acc: 0.8478 - val_loss: 0.3644 - val_acc: 0.8445\n",
      "Epoch 29/50\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.3792 - acc: 0.8500 - val_loss: 0.3651 - val_acc: 0.8450\n",
      "Epoch 30/50\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.3746 - acc: 0.8543 - val_loss: 0.3659 - val_acc: 0.8465\n",
      "Epoch 31/50\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.3757 - acc: 0.8516 - val_loss: 0.3659 - val_acc: 0.8455\n",
      "Epoch 32/50\n",
      "14000/14000 [==============================] - 1s 68us/step - loss: 0.3705 - acc: 0.8532 - val_loss: 0.3672 - val_acc: 0.8487\n",
      "Epoch 33/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.3765 - acc: 0.8501 - val_loss: 0.3668 - val_acc: 0.8460\n",
      "Epoch 34/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.3718 - acc: 0.8516 - val_loss: 0.3671 - val_acc: 0.8453\n",
      "Epoch 35/50\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.3662 - acc: 0.8564 - val_loss: 0.3684 - val_acc: 0.8445\n",
      "Epoch 36/50\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.3657 - acc: 0.8581 - val_loss: 0.3708 - val_acc: 0.8448\n",
      "Epoch 37/50\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.3630 - acc: 0.8606 - val_loss: 0.3709 - val_acc: 0.8437\n",
      "Epoch 38/50\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.3649 - acc: 0.8584 - val_loss: 0.3710 - val_acc: 0.8458\n",
      "Epoch 39/50\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.3639 - acc: 0.8570 - val_loss: 0.3709 - val_acc: 0.8467\n",
      "Epoch 40/50\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.3588 - acc: 0.8601 - val_loss: 0.3710 - val_acc: 0.8463\n",
      "Epoch 41/50\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.3578 - acc: 0.8619 - val_loss: 0.3724 - val_acc: 0.8465\n",
      "Epoch 42/50\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.3528 - acc: 0.8621 - val_loss: 0.3737 - val_acc: 0.8445\n",
      "Epoch 43/50\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.3570 - acc: 0.8565 - val_loss: 0.3728 - val_acc: 0.8448\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.3526 - acc: 0.8647 - val_loss: 0.3741 - val_acc: 0.8462\n",
      "Epoch 45/50\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.3488 - acc: 0.8671 - val_loss: 0.3746 - val_acc: 0.8455\n",
      "Epoch 46/50\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.3566 - acc: 0.8606 - val_loss: 0.3747 - val_acc: 0.8452\n",
      "Epoch 47/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.3563 - acc: 0.8617 - val_loss: 0.3732 - val_acc: 0.8452\n",
      "Epoch 48/50\n",
      "14000/14000 [==============================] - 1s 65us/step - loss: 0.3490 - acc: 0.8684 - val_loss: 0.3754 - val_acc: 0.8468\n",
      "Epoch 49/50\n",
      "14000/14000 [==============================] - 1s 67us/step - loss: 0.3488 - acc: 0.8676 - val_loss: 0.3747 - val_acc: 0.8455\n",
      "Epoch 50/50\n",
      "14000/14000 [==============================] - 1s 66us/step - loss: 0.3460 - acc: 0.8690 - val_loss: 0.3752 - val_acc: 0.8445\n",
      "Model 3 test score: 0.3806348338127136\n",
      "Model 3 test accuracy: 0.849\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Time for 3 layers!\n",
    "model3 = Sequential()\n",
    "\n",
    "# The first fully connected layer with 140 units\n",
    "model3.add(Dense(140, input_shape=(training_features.shape[1],)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "# Drop out 40% of units for regularization\n",
    "model3.add(Dropout(0.75))\n",
    "\n",
    "# A second fully connected layer with 60 units\n",
    "model3.add(Dense(60, input_shape=(training_features.shape[1],)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "# Drop out 25% of units for regularization\n",
    "model3.add(Dropout(0.75))\n",
    "\n",
    "# A third fully connected layer with 60 units\n",
    "model3.add(Dense(25, input_shape=(training_features.shape[1],)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "# Drop out 10% of units for regularization\n",
    "model3.add(Dropout(0.50))\n",
    "\n",
    "# Softmax classification layer\n",
    "model3.add(Dense(2))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "## Printing a summary of the layers and weights in your model\n",
    "model3.summary()\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "fit = model3.fit(training_features, training_labels, batch_size=256, epochs=50, verbose=1,\n",
    "                 validation_data=(validation_features, validation_labels))\n",
    "\n",
    "score3 = model3.evaluate(validation_features, validation_labels, verbose=0)\n",
    "print('Model 3 test score:', score2[0])\n",
    "print('Model 3 test accuracy:', score2[1])\n",
    "\n",
    "if score3 > best_score:\n",
    "    best_score = score3\n",
    "    best_model = model3\n",
    "    best_num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 test score: 0.37847813268502556\n",
      "Model 1 test accuracy: 0.8496666666666667\n",
      "Model 2 test score: 0.3806348338127136\n",
      "Model 2 test accuracy: 0.849\n",
      "Model 3 test score: 0.3751704444885254\n",
      "Model 3 test accuracy: 0.8445\n"
     ]
    }
   ],
   "source": [
    "score1 = model1.evaluate(validation_features, validation_labels, verbose=0)\n",
    "print('Model 1 test score:', score1[0])\n",
    "print('Model 1 test accuracy:', score1[1])\n",
    "\n",
    "score2 = model2.evaluate(validation_features, validation_labels, verbose=0)\n",
    "print('Model 2 test score:', score2[0])\n",
    "print('Model 2 test accuracy:', score2[1])\n",
    "\n",
    "score3 = model3.evaluate(validation_features, validation_labels, verbose=0)\n",
    "print('Model 3 test score:', score3[0])\n",
    "print('Model 3 test accuracy:', score3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.3001 - acc: 0.8835\n",
      "Epoch 2/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2970 - acc: 0.8836\n",
      "Epoch 3/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2912 - acc: 0.8878\n",
      "Epoch 4/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2868 - acc: 0.8884\n",
      "Epoch 5/30\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 0.2798 - acc: 0.8918\n",
      "Epoch 6/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2772 - acc: 0.8950\n",
      "Epoch 7/30\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.2755 - acc: 0.8910\n",
      "Epoch 8/30\n",
      "20000/20000 [==============================] - 1s 55us/step - loss: 0.2686 - acc: 0.8975\n",
      "Epoch 9/30\n",
      "20000/20000 [==============================] - 1s 53us/step - loss: 0.2661 - acc: 0.8994\n",
      "Epoch 10/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2634 - acc: 0.8998\n",
      "Epoch 11/30\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 0.2640 - acc: 0.9002\n",
      "Epoch 12/30\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 0.2565 - acc: 0.9032\n",
      "Epoch 13/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2562 - acc: 0.9030\n",
      "Epoch 14/30\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 0.2464 - acc: 0.9057\n",
      "Epoch 15/30\n",
      "20000/20000 [==============================] - 1s 55us/step - loss: 0.2517 - acc: 0.9054\n",
      "Epoch 16/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2478 - acc: 0.9078\n",
      "Epoch 17/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2444 - acc: 0.9080\n",
      "Epoch 18/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2388 - acc: 0.9107: 0s - loss: 0.\n",
      "Epoch 19/30\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.2404 - acc: 0.9114: 0s - loss: 0.\n",
      "Epoch 20/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2371 - acc: 0.9121\n",
      "Epoch 21/30\n",
      "20000/20000 [==============================] - 1s 55us/step - loss: 0.2343 - acc: 0.9113\n",
      "Epoch 22/30\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 0.2336 - acc: 0.9131\n",
      "Epoch 23/30\n",
      "20000/20000 [==============================] - 1s 55us/step - loss: 0.2298 - acc: 0.9123\n",
      "Epoch 24/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2297 - acc: 0.9163\n",
      "Epoch 25/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2304 - acc: 0.9158\n",
      "Epoch 26/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2277 - acc: 0.9153\n",
      "Epoch 27/30\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.2225 - acc: 0.9190\n",
      "Epoch 28/30\n",
      "20000/20000 [==============================] - 1s 53us/step - loss: 0.2178 - acc: 0.9221\n",
      "Epoch 29/30\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2158 - acc: 0.9217\n",
      "Epoch 30/30\n",
      "20000/20000 [==============================] - 1s 58us/step - loss: 0.2149 - acc: 0.9217\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "%i format: a number is required, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-740f72816d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dibidave/caltech-cs155/central-nervous-system/project1/utils.py\u001b[0m in \u001b[0;36msave_prediction\u001b[0;34m(labels, filename)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%i,%i\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: %i format: a number is required, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# Now the whole dataset with the best model\n",
    "\n",
    "training_features, training_labels, _, _ = utils.get_training_data(onehot=True, standardize=True, validation_size=0.0)\n",
    "\n",
    "best_model.fit(training_features, training_labels, batch_size=256, epochs=best_num_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = utils.get_test_data(standardize=True)\n",
    "\n",
    "test_labels = best_model.predict_classes(test_features)\n",
    "\n",
    "utils.save_prediction(test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
