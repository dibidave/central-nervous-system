{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, training_labels, validation_features, validation_labels = \\\n",
    "    utils.get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 100,302\n",
      "Trainable params: 100,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/15\n",
      "14000/14000 [==============================] - 1s 36us/step - loss: 0.4995 - acc: 0.7723 - val_loss: 0.3993 - val_acc: 0.8273\n",
      "Epoch 2/15\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.3522 - acc: 0.8547 - val_loss: 0.3653 - val_acc: 0.8422\n",
      "Epoch 3/15\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.3145 - acc: 0.8727 - val_loss: 0.3624 - val_acc: 0.8430\n",
      "Epoch 4/15\n",
      "14000/14000 [==============================] - 0s 34us/step - loss: 0.2874 - acc: 0.8848 - val_loss: 0.3686 - val_acc: 0.8442\n",
      "Epoch 5/15\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.2705 - acc: 0.8904 - val_loss: 0.3741 - val_acc: 0.8392\n",
      "Epoch 6/15\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.2523 - acc: 0.9020 - val_loss: 0.3816 - val_acc: 0.8403\n",
      "Epoch 7/15\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.2373 - acc: 0.9052 - val_loss: 0.3842 - val_acc: 0.8387\n",
      "Epoch 8/15\n",
      "14000/14000 [==============================] - 0s 31us/step - loss: 0.2211 - acc: 0.9151 - val_loss: 0.3908 - val_acc: 0.8397\n",
      "Epoch 9/15\n",
      "14000/14000 [==============================] - 1s 36us/step - loss: 0.2043 - acc: 0.9218 - val_loss: 0.3999 - val_acc: 0.8375\n",
      "Epoch 10/15\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.1911 - acc: 0.9277 - val_loss: 0.4063 - val_acc: 0.8387\n",
      "Epoch 11/15\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.1756 - acc: 0.9363 - val_loss: 0.4190 - val_acc: 0.8358\n",
      "Epoch 12/15\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.1648 - acc: 0.9390 - val_loss: 0.4302 - val_acc: 0.8382\n",
      "Epoch 13/15\n",
      "14000/14000 [==============================] - 0s 33us/step - loss: 0.1511 - acc: 0.9455 - val_loss: 0.4388 - val_acc: 0.8378\n",
      "Epoch 14/15\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.1366 - acc: 0.9533 - val_loss: 0.4484 - val_acc: 0.8368\n",
      "Epoch 15/15\n",
      "14000/14000 [==============================] - 0s 30us/step - loss: 0.1278 - acc: 0.9578 - val_loss: 0.4621 - val_acc: 0.8357\n"
     ]
    }
   ],
   "source": [
    "# Our first 100-unit model for Problem C\n",
    "model1 = Sequential()\n",
    "\n",
    "# A single fully connected layer with 100 units\n",
    "model1.add(Dense(100, input_shape=(training_features.shape[1],)))\n",
    "model1.add(Activation('relu'))\n",
    "\n",
    "# Drop out 10% of units for regularization\n",
    "model1.add(Dropout(0.3))\n",
    "\n",
    "# Softmax classification layer\n",
    "model1.add(Dense(2))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "## Printing a summary of the layers and weights in your model\n",
    "model1.summary()\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "fit = model1.fit(training_features, training_labels, batch_size=256, epochs=15, verbose=1,\n",
    "                 validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 160)               160160    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 40)                6440      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 82        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 166,682\n",
      "Trainable params: 166,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "14000/14000 [==============================] - 1s 46us/step - loss: 0.4951 - acc: 0.7671 - val_loss: 0.3825 - val_acc: 0.8315\n",
      "Epoch 2/30\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.3475 - acc: 0.8556 - val_loss: 0.3684 - val_acc: 0.8427\n",
      "Epoch 3/30\n",
      "14000/14000 [==============================] - 1s 39us/step - loss: 0.2987 - acc: 0.8786 - val_loss: 0.3681 - val_acc: 0.8438\n",
      "Epoch 4/30\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.2642 - acc: 0.8926 - val_loss: 0.3820 - val_acc: 0.8388\n",
      "Epoch 5/30\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.2291 - acc: 0.9084 - val_loss: 0.4027 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.1935 - acc: 0.9249 - val_loss: 0.4296 - val_acc: 0.8398\n",
      "Epoch 7/30\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.1636 - acc: 0.9380 - val_loss: 0.4592 - val_acc: 0.8368\n",
      "Epoch 8/30\n",
      "14000/14000 [==============================] - 1s 39us/step - loss: 0.1345 - acc: 0.9515 - val_loss: 0.4965 - val_acc: 0.8365\n",
      "Epoch 9/30\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.1090 - acc: 0.9594 - val_loss: 0.5378 - val_acc: 0.8342\n",
      "Epoch 10/30\n",
      "14000/14000 [==============================] - 1s 46us/step - loss: 0.0845 - acc: 0.9704 - val_loss: 0.5915 - val_acc: 0.8385\n",
      "Epoch 11/30\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 0.0663 - acc: 0.9782 - val_loss: 0.6423 - val_acc: 0.8360\n",
      "Epoch 12/30\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.0536 - acc: 0.9834 - val_loss: 0.7110 - val_acc: 0.8337\n",
      "Epoch 13/30\n",
      "14000/14000 [==============================] - 1s 49us/step - loss: 0.0405 - acc: 0.9864 - val_loss: 0.7834 - val_acc: 0.8355\n",
      "Epoch 14/30\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.0352 - acc: 0.9888 - val_loss: 0.8406 - val_acc: 0.8332\n",
      "Epoch 15/30\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.0283 - acc: 0.9910 - val_loss: 0.8497 - val_acc: 0.8308\n",
      "Epoch 16/30\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.8935 - val_acc: 0.8323\n",
      "Epoch 17/30\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.0197 - acc: 0.9934 - val_loss: 0.9335 - val_acc: 0.8358\n",
      "Epoch 18/30\n",
      "14000/14000 [==============================] - 1s 42us/step - loss: 0.0167 - acc: 0.9947 - val_loss: 0.9713 - val_acc: 0.8342\n",
      "Epoch 19/30\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.0150 - acc: 0.9954 - val_loss: 1.0036 - val_acc: 0.8340\n",
      "Epoch 20/30\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.0136 - acc: 0.9957 - val_loss: 1.0811 - val_acc: 0.8325\n",
      "Epoch 21/30\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.0106 - acc: 0.9966 - val_loss: 1.0963 - val_acc: 0.8327\n",
      "Epoch 22/30\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.0095 - acc: 0.9974 - val_loss: 1.1077 - val_acc: 0.8342\n",
      "Epoch 23/30\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.0134 - acc: 0.9967 - val_loss: 1.1185 - val_acc: 0.8318\n",
      "Epoch 24/30\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.0073 - acc: 0.9975 - val_loss: 1.1698 - val_acc: 0.8328\n",
      "Epoch 25/30\n",
      "14000/14000 [==============================] - 1s 39us/step - loss: 0.0065 - acc: 0.9975 - val_loss: 1.1967 - val_acc: 0.8320\n",
      "Epoch 26/30\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.0105 - acc: 0.9971 - val_loss: 1.1667 - val_acc: 0.8342\n",
      "Epoch 27/30\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.0080 - acc: 0.9978 - val_loss: 1.1948 - val_acc: 0.8337\n",
      "Epoch 28/30\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.0088 - acc: 0.9973 - val_loss: 1.2106 - val_acc: 0.8302\n",
      "Epoch 29/30\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.0055 - acc: 0.9982 - val_loss: 1.2281 - val_acc: 0.8307\n",
      "Epoch 30/30\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.0064 - acc: 0.9979 - val_loss: 1.2486 - val_acc: 0.8325\n"
     ]
    }
   ],
   "source": [
    "# Let's crank up the layers\n",
    "model2 = Sequential()\n",
    "\n",
    "# The first fully connected layer with 140 units\n",
    "model2.add(Dense(160, input_shape=(training_features.shape[1],)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "# Drop out 30% of units for regularization\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "# A second fully connected layer with 60 units\n",
    "model2.add(Dense(40, input_shape=(training_features.shape[1],)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "# Drop out 10% of units for regularization\n",
    "model2.add(Dropout(0.1))\n",
    "\n",
    "# Softmax classification layer\n",
    "model2.add(Dense(2))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "## Printing a summary of the layers and weights in your model\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "fit = model2.fit(training_features, training_labels, batch_size=256, epochs=30, verbose=1,\n",
    "                 validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 25)                100       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 52        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 107,177\n",
      "Trainable params: 106,827\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "14000/14000 [==============================] - 1s 64us/step - loss: 1.0806 - acc: 0.5137 - val_loss: 0.6647 - val_acc: 0.6192\n",
      "Epoch 2/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.9039 - acc: 0.5220 - val_loss: 0.6606 - val_acc: 0.6122\n",
      "Epoch 3/100\n",
      "14000/14000 [==============================] - 1s 42us/step - loss: 0.7998 - acc: 0.5330 - val_loss: 0.6597 - val_acc: 0.6113\n",
      "Epoch 4/100\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 0.7201 - acc: 0.5623 - val_loss: 0.6563 - val_acc: 0.6220\n",
      "Epoch 5/100\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.6880 - acc: 0.5810 - val_loss: 0.6466 - val_acc: 0.6410\n",
      "Epoch 6/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.6499 - acc: 0.6246 - val_loss: 0.6213 - val_acc: 0.6725\n",
      "Epoch 7/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.6116 - acc: 0.6668 - val_loss: 0.5825 - val_acc: 0.7005\n",
      "Epoch 8/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.5780 - acc: 0.7056 - val_loss: 0.5340 - val_acc: 0.7353\n",
      "Epoch 9/100\n",
      "14000/14000 [==============================] - 1s 42us/step - loss: 0.5384 - acc: 0.7406 - val_loss: 0.4841 - val_acc: 0.7707\n",
      "Epoch 10/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.5201 - acc: 0.7559 - val_loss: 0.4497 - val_acc: 0.7915\n",
      "Epoch 11/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.5020 - acc: 0.7705 - val_loss: 0.4247 - val_acc: 0.8085\n",
      "Epoch 12/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.4748 - acc: 0.7883 - val_loss: 0.4112 - val_acc: 0.8113\n",
      "Epoch 13/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.4663 - acc: 0.8020 - val_loss: 0.3894 - val_acc: 0.8283\n",
      "Epoch 14/100\n",
      "14000/14000 [==============================] - 1s 42us/step - loss: 0.4434 - acc: 0.8129 - val_loss: 0.3806 - val_acc: 0.8340\n",
      "Epoch 15/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.4408 - acc: 0.8160 - val_loss: 0.3776 - val_acc: 0.8343\n",
      "Epoch 16/100\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 0.4283 - acc: 0.8261 - val_loss: 0.3727 - val_acc: 0.8387\n",
      "Epoch 17/100\n",
      "14000/14000 [==============================] - 1s 48us/step - loss: 0.4271 - acc: 0.8301 - val_loss: 0.3699 - val_acc: 0.8395\n",
      "Epoch 18/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.4174 - acc: 0.8357 - val_loss: 0.3714 - val_acc: 0.8400\n",
      "Epoch 19/100\n",
      "14000/14000 [==============================] - 1s 46us/step - loss: 0.4085 - acc: 0.8409 - val_loss: 0.3707 - val_acc: 0.8412\n",
      "Epoch 20/100\n",
      "14000/14000 [==============================] - 1s 42us/step - loss: 0.3973 - acc: 0.8450 - val_loss: 0.3723 - val_acc: 0.8398\n",
      "Epoch 21/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.3959 - acc: 0.8494 - val_loss: 0.3721 - val_acc: 0.8408\n",
      "Epoch 22/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.3891 - acc: 0.8526 - val_loss: 0.3733 - val_acc: 0.8408\n",
      "Epoch 23/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.3762 - acc: 0.8590 - val_loss: 0.3792 - val_acc: 0.8387\n",
      "Epoch 24/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.3745 - acc: 0.8612 - val_loss: 0.3762 - val_acc: 0.8427\n",
      "Epoch 25/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.3710 - acc: 0.8620 - val_loss: 0.3759 - val_acc: 0.8440\n",
      "Epoch 26/100\n",
      "14000/14000 [==============================] - 1s 45us/step - loss: 0.3659 - acc: 0.8648 - val_loss: 0.3791 - val_acc: 0.8450\n",
      "Epoch 27/100\n",
      "14000/14000 [==============================] - 1s 45us/step - loss: 0.3627 - acc: 0.8647 - val_loss: 0.3841 - val_acc: 0.8418\n",
      "Epoch 28/100\n",
      "14000/14000 [==============================] - 1s 45us/step - loss: 0.3605 - acc: 0.8662 - val_loss: 0.3838 - val_acc: 0.8435\n",
      "Epoch 29/100\n",
      "14000/14000 [==============================] - 1s 42us/step - loss: 0.3634 - acc: 0.8694 - val_loss: 0.3841 - val_acc: 0.8440\n",
      "Epoch 30/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.3539 - acc: 0.8697 - val_loss: 0.3851 - val_acc: 0.8420\n",
      "Epoch 31/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.3502 - acc: 0.8691 - val_loss: 0.3879 - val_acc: 0.8420\n",
      "Epoch 32/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.3389 - acc: 0.8757 - val_loss: 0.3905 - val_acc: 0.8423\n",
      "Epoch 33/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.3325 - acc: 0.8789 - val_loss: 0.3939 - val_acc: 0.8417\n",
      "Epoch 34/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.3423 - acc: 0.8748 - val_loss: 0.3938 - val_acc: 0.8430\n",
      "Epoch 35/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.3376 - acc: 0.8780 - val_loss: 0.3983 - val_acc: 0.8412\n",
      "Epoch 36/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.3275 - acc: 0.8839 - val_loss: 0.4004 - val_acc: 0.8443\n",
      "Epoch 37/100\n",
      "14000/14000 [==============================] - 1s 44us/step - loss: 0.3373 - acc: 0.8806 - val_loss: 0.4030 - val_acc: 0.8422\n",
      "Epoch 38/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.3246 - acc: 0.8835 - val_loss: 0.4035 - val_acc: 0.8423\n",
      "Epoch 39/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.3222 - acc: 0.8814 - val_loss: 0.4059 - val_acc: 0.8418\n",
      "Epoch 40/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.3208 - acc: 0.8824 - val_loss: 0.4066 - val_acc: 0.8400\n",
      "Epoch 41/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.3180 - acc: 0.8841 - val_loss: 0.4094 - val_acc: 0.8417\n",
      "Epoch 42/100\n",
      "14000/14000 [==============================] - 1s 51us/step - loss: 0.3214 - acc: 0.8856 - val_loss: 0.4117 - val_acc: 0.8415\n",
      "Epoch 43/100\n",
      "14000/14000 [==============================] - 1s 47us/step - loss: 0.3161 - acc: 0.8852 - val_loss: 0.4151 - val_acc: 0.8427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "14000/14000 [==============================] - 1s 43us/step - loss: 0.3107 - acc: 0.8894 - val_loss: 0.4147 - val_acc: 0.8412\n",
      "Epoch 45/100\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.3039 - acc: 0.8899 - val_loss: 0.4199 - val_acc: 0.8418\n",
      "Epoch 46/100\n",
      "14000/14000 [==============================] - 1s 39us/step - loss: 0.3063 - acc: 0.8914 - val_loss: 0.4241 - val_acc: 0.8415\n",
      "Epoch 47/100\n",
      "14000/14000 [==============================] - 1s 41us/step - loss: 0.3043 - acc: 0.8931 - val_loss: 0.4290 - val_acc: 0.8407\n",
      "Epoch 48/100\n",
      "14000/14000 [==============================] - 1s 40us/step - loss: 0.3064 - acc: 0.8906 - val_loss: 0.4362 - val_acc: 0.8405\n",
      "Epoch 49/100\n",
      "  256/14000 [..............................] - ETA: 0s - loss: 0.2201 - acc: 0.9219"
     ]
    }
   ],
   "source": [
    "\n",
    "# Time for 3 layers!\n",
    "model3 = Sequential()\n",
    "\n",
    "# The first fully connected layer with 140 units\n",
    "model3.add(Dense(100, input_shape=(training_features.shape[1],)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "# Drop out 40% of units for regularization\n",
    "model3.add(Dropout(0.75))\n",
    "\n",
    "# A second fully connected layer with 60 units\n",
    "model3.add(Dense(50, input_shape=(training_features.shape[1],)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "# Drop out 25% of units for regularization\n",
    "model3.add(Dropout(0.75))\n",
    "\n",
    "# A third fully connected layer with 60 units\n",
    "model3.add(Dense(25, input_shape=(training_features.shape[1],)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "# Drop out 10% of units for regularization\n",
    "model3.add(Dropout(0.75))\n",
    "\n",
    "# Softmax classification layer\n",
    "model3.add(Dense(2))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "## Printing a summary of the layers and weights in your model\n",
    "model3.summary()\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "fit = model3.fit(training_features, training_labels, batch_size=256, epochs=100, verbose=1,\n",
    "                 validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model1.evaluate(validation_features, validation_labels, verbose=0)\n",
    "print('Model 1 test score:', score[0])\n",
    "print('Model 1 test accuracy:', score[1])\n",
    "\n",
    "score = model2.evaluate(validation_features, validation_labels, verbose=0)\n",
    "print('Model 2 test score:', score[0])\n",
    "print('Model 2 test accuracy:', score[1])\n",
    "\n",
    "score = model3.evaluate(validation_features, validation_labels, verbose=0)\n",
    "print('Model 3 test score:', score[0])\n",
    "print('Model 3 test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
