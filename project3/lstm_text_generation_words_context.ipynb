{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sonnet 99 is not 14 lines, skipping\n",
      "Sonnet 126 is not 14 lines, skipping\n",
      "corpus length: 19972\n",
      "total words: 3160\n",
      "nb sequences: 19964\n",
      "Vectorization...\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "### https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "''' Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "from Sonnet_Set import Sonnet_Set\n",
    "from Sonnet_Set import Sequence_Type\n",
    "from Sonnet_Set import Element_Type\n",
    "\n",
    "sonnet_set = Sonnet_Set(\"data/shakespeare.txt\")\n",
    "sonnets = open(\"data/shakespeare.txt\")\n",
    "sonnet_sequences = sonnet_set.get_sequences(sequence_type=Sequence_Type.SONNET, element_type=Element_Type.WORD)\n",
    "\n",
    "text =[word for sonnet in sonnet_sequences for word in sonnet]\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "words = sorted(list(set(text)))\n",
    "print('total words:', len(words))\n",
    "word_indices = dict((w, i) for i, w in enumerate(words))\n",
    "indices_word = dict((i, w) for i, w in enumerate(words))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 8\n",
    "step = 1\n",
    "sentences = []\n",
    "next_words = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_words.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(words)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(words)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, word in enumerate(sentence):\n",
    "        x[i, t, word_indices[word]] = 1\n",
    "    y[i, word_indices[next_words[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(words))))\n",
    "model.add(Dense(len(words)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/models.py:944: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "19964/19964 [==============================] - 86s 4ms/step - loss: 6.3904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce94b905c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "         batch_size=128,\n",
    "         nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sonnets = len(sonnet_sequences)\n",
    "num_words = len(words)\n",
    "        \n",
    "\n",
    "# Calculate sonnet context vectors\n",
    "\n",
    "sonnet_contexts = np.zeros((num_sonnets, num_words))\n",
    "\n",
    "for sonnet_index, sonnet in enumerate(sonnet_sequences):\n",
    "    for word in sonnet:\n",
    "        sonnet_contexts[sonnet_index, word] += 1\n",
    "\n",
    "row_sums = sonnet_contexts.sum(axis=1)\n",
    "sonnet_contexts = sonnet_contexts / row_sums[:, np.newaxis]\n",
    "\n",
    "column_means = sonnet_contexts.mean(axis=0)\n",
    "column_sds = sonnet_contexts.std(axis=0)\n",
    "\n",
    "sonnet_contexts = sonnet_contexts - column_means[np.newaxis, :]\n",
    "sonnet_contexts = sonnet_contexts / column_sds[np.newaxis, :]\n",
    "\n",
    "def calculate_word_sequence_context(word_sequence):\n",
    "    \n",
    "    word_sequence_context = np.zeros((num_words,))\n",
    "    \n",
    "    for word in word_sequence:\n",
    "        word_sequence_context[word] += 1\n",
    "    \n",
    "    word_sequence_context = word_sequence_context / sum(word_sequence_context)\n",
    "    \n",
    "    word_sequence_context = word_sequence_context - column_means\n",
    "    word_sequence_context = word_sequence_context / column_sds\n",
    "    \n",
    "    return word_sequence_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- diversity: 0.25\n",
      "----- Generating with seed -----\n",
      "Thy sweet virtue answer not thy show:\n",
      ":\n",
      ":\n",
      ".\n",
      "----- End seed -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanishing hoisted richly subdued speed,\n",
      "Beast diest duteous canst bark i'll ashes mother,\n",
      "Cast preserve table grind kill absent speed,\n",
      "Prime get died enmity carry that another:\n",
      "Gate essays imprisoned error error friend,\n",
      "Cheap poets rest record false-speaking seek,\n",
      "Dial's fist ladies heart's adore get spend,\n",
      "Dye alteration askance long-lived seek:\n",
      "Mourn measured bark times sometimes bears end shame,\n",
      "Looked light posting lived slept candles idle arising,\n",
      "Spur went stars idolatry bearer blame,\n",
      "Run revenge measured beast gardens bestow arising:\n",
      "  Jade measured supposed when motley fell grind,\n",
      "  Flesh going mounted faring neigh instinct grind.\n",
      "----- diversity: 0.75\n",
      "----- Generating with seed -----\n",
      "Thy sweet virtue answer not thy show:\n",
      ":\n",
      ":\n",
      ".\n",
      "----- End seed -----\n",
      "Wet disposed beshrew sullied spent precious nought,\n",
      "Latch sportive tend pricked bars belongs bequest convert,\n",
      "Largess gives defy suppose sportive thought,\n",
      "Slavery increase world-without-end become heart:\n",
      "Torture return absent down grieve flower wing,\n",
      "Bail leave depart frank betray translated canopy,\n",
      "Hiding receive sue pricked wounded transport bring,\n",
      "Untrue form betraying grave how ragged eternity:\n",
      "Touches self-doing mark bar accumulate take,\n",
      "Counting comment absence whoe'er deserved car,\n",
      "Healthful plague soundless o lark smiling forsake,\n",
      "Sparkling golden wastes watching vassal car:\n",
      "  Given begin enjoy west walks centre anticipate,\n",
      "  Miracle becoming slide enjoys fate.\n",
      "----- diversity: 1.5\n",
      "----- Generating with seed -----\n",
      "Thy sweet virtue answer not thy show:\n",
      ":\n",
      ":\n",
      ".\n",
      "----- End seed -----\n",
      "There's plea gravity cut stout applying being,\n",
      "Enjoy charged almost eyelids perfumed lips,\n",
      "Thing niggard lets bequest masked strongly 'greeing,\n",
      "Deaths whit shape unwooed run proclaims save lips:\n",
      "Building warm wanton registers fleet'st rehearse,\n",
      "Wretched sweet-seasoned settled correction staineth,\n",
      "Deserts fawn tender sea jewels staineth inhearse,\n",
      "Devour long-lived here debateth touched disdaineth:\n",
      "Advised dust love-suit contrary onward growing,\n",
      "Alchemy guard banquet antique begins yore,\n",
      "Mountain truant hours effectually growing,\n",
      "Love-suit resemble drugs ransom princes abhor:\n",
      "  Slander commend horse cold nurse reserve dead,\n",
      "  Welcome added lesser birds forty bred.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Generating with some sensicalness\n",
    "\n",
    "random_sonnet_index = np.random.choice(range(len(sonnet_sequences)))\n",
    "random_sonnet = sonnet_sequences[random_sonnet_index]\n",
    "\n",
    "num_sonnets_to_compare_to = 5\n",
    "context_weight = 1\n",
    "\n",
    "# Pick the end of a line - this should serve as a decent seed for starting a new poem\n",
    "sentence = random_sonnet[-maxlen - 1:-1]\n",
    "\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "for diversity in [0.25, 0.75, 1.5]:\n",
    "    print('----- diversity:', diversity)\n",
    "    \n",
    "    print(\"----- Generating with seed -----\")\n",
    "    sonnet_set.print_sonnet(sentence, sequence_type=Sequence_Type.SONNET, element_type=Element_Type.WORD)\n",
    "    print('----- End seed -----')\n",
    "    \n",
    "    current_phrase_window = sentence[:]\n",
    "    generated_sonnet = []\n",
    "    current_sonnet_line = 0\n",
    "    num_syllables_this_line = 0\n",
    "    previous_rhymable_words = [None, None]\n",
    "    \n",
    "    rhyming_words_vector = [1 if i in sonnet_set._rhyme_dictionary.keys() else 0 for i in range(len(words))]\n",
    "    not_new_line_vector = [1 if i < sonnet_set._word_dictionary[Sonnet_Set.NEW_LINE_CHARACTER]\n",
    "                           else 0 for i in range(len(words))]\n",
    "\n",
    "    while current_sonnet_line < 14:\n",
    "        \n",
    "        x_pred = np.zeros((1, maxlen, len(words)))\n",
    "        \n",
    "        for t, word in enumerate(current_phrase_window):\n",
    "            x_pred[0, t, word_indices[word]] = 1.\n",
    "        \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "        if current_sonnet_line > 1:\n",
    "            word_sequence_context = calculate_word_sequence_context(generated_sonnet)\n",
    "            sonnet_similarities = np.zeros((num_sonnets,))\n",
    "            for sonnet_index, sonnet in enumerate(sonnet_sequences):\n",
    "                sonnet_similarity = np.matmul(word_sequence_context.T, sonnet_contexts[sonnet_index].T)\n",
    "                sonnet_similarities[sonnet_index] = sonnet_similarity\n",
    "            most_similar_sonnets = sonnet_similarities.argsort()[-num_sonnets_to_compare_to:][::-1]\n",
    "            least_similar_sonnets = sonnet_similarities.argsort()[0:num_sonnets_to_compare_to]\n",
    "            \n",
    "            context_weights = np.array((num_words,))\n",
    "            \n",
    "            for sonnet_index in most_similar_sonnets:\n",
    "                context_weights = context_weights + sonnet_contexts[sonnet_index]\n",
    "            \n",
    "            for sonnet_index in least_similar_sonnets:\n",
    "                context_weights = context_weights - sonnet_contexts[sonnet_index]\n",
    "            \n",
    "            context_weights = (context_weights - context_weights.min()) / context_weights.max()\n",
    "            \n",
    "            context_weights = context_weights / context_weights.sum()\n",
    "            \n",
    "            preds = (1 - context_weight) * preds + (context_weight * context_weights)\n",
    "        \n",
    "        # If we're on the last syllable, this must be a rhymable word\n",
    "        if num_syllables_this_line >= 9:\n",
    "            if current_sonnet_line in [0, 1, 4, 5, 8, 9, 12]:\n",
    "                preds = np.multiply(preds, rhyming_words_vector)\n",
    "                next_word = sample(preds, diversity)\n",
    "                if current_sonnet_line in [0, 4, 8, 12]:\n",
    "                    previous_rhymable_words[0] = next_word\n",
    "                else:\n",
    "                    previous_rhymable_words[1] = next_word\n",
    "            \n",
    "                #print(\"Next rhymable word is '%s'\" % sonnet_set._word_list[next_word])\n",
    "            elif current_sonnet_line in [2, 3, 6, 7, 10, 11, 13]:\n",
    "                \n",
    "                if current_sonnet_line in [2, 6, 10, 13]:\n",
    "                    previous_rhymable_word = previous_rhymable_words[0]\n",
    "                else:\n",
    "                    previous_rhymable_word = previous_rhymable_words[1]\n",
    "                    \n",
    "                rhyme_partners = sonnet_set._rhyme_pairs[sonnet_set._rhyme_dictionary[previous_rhymable_word]]\n",
    "                rhyme_partner_vector = [1 if i in rhyme_partners else 0 for i in range(len(preds))]\n",
    "                preds = np.multiply(preds, rhyme_partner_vector)\n",
    "                next_word = sample(preds, diversity)\n",
    "                previous_rhymable_word = None\n",
    "            \n",
    "                #print(\"Next rhyming word is '%s'\" % sonnet_set._word_list[next_word])\n",
    "            current_phrase_window = current_phrase_window[1:]+[next_word]\n",
    "            generated_sonnet.append(next_word)\n",
    "            num_syllables_this_line += sonnet_set._syllable_list_num[next_word][0]\n",
    "            next_word = sonnet_set._word_dictionary[Sonnet_Set.NEW_LINE_CHARACTER]\n",
    "            current_sonnet_line += 1\n",
    "            num_syllables_this_line = 0\n",
    "        else:\n",
    "            preds = np.multiply(preds, not_new_line_vector)\n",
    "            next_word = sample(preds, diversity)\n",
    "            num_syllables_this_line += sonnet_set._syllable_list_num[next_word][0]\n",
    "            \n",
    "            #print(\"Next word is '%s'\" % sonnet_set._word_list[next_word])\n",
    "            \n",
    "        current_phrase_window = current_phrase_window[1:]+[next_word]\n",
    "        generated_sonnet.append(next_word)\n",
    "        \n",
    "    #print(generated_sonnet)\n",
    "\n",
    "    sonnet_set.print_sonnet(generated_sonnet, sequence_type=Sequence_Type.SONNET, element_type=Element_Type.WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(sonnet_set._character_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
