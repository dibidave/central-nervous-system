{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sonnet 99 is not 14 lines, skipping\n",
      "Sonnet 126 is not 14 lines, skipping\n",
      "[[1], [2], [2], [1], [2], [2], [1], [2], [2], [1], [1], [1, 2], [1], [1], [1], [1], [2], [1], [1], [1], [2], [1], [2], [1], [1], [3], [1], [3], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [4], [1], [1, 2], [1], [2], [1], [3], [1], [1], [1], [1], [1], [1, 2], [1], [1], [1], [1], [3], [1], [2], [2], [2], [1], [2], [1], [2], [2], [1], [1], [1], [1], [3], [2], [1], [1], [1], [1], [2], [1], [1], [1], [1], [1], [1], [2], [2], [1], [2], [1], [1], [1], [2], [1], [1], [1], [3], [1], [1], [1], [1], [2], [1], [1], [1], [1], [1], [1], [1, 2], [1], [1], [2], [1, 2], [2], [1], [1], [2], [1], [1], [3], [1], [2], [1], [1], [1], [1], [2], [1], [1], [1], [2], [1], [1], [1], [1], [1], [1], [1], [1], [2], [2], [3], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1], [1, 2], [1], [1], [2, 3], [1], [2], [1], [2, 3], [1], [2], [2], [1], [1, 2], [1], [1], [2], [1], [2], [2], [3], [1], [1], [1], [1], [2], [1], [4], [2], [1], [1], [2], [2], [1], [1], [1], [2], [1], [1], [2], [2], [2], [1], [3, 4], [2], [2], [1], [3], [3], [1], [1], [2], [3], [2], [2], [1], [1, 2], [1], [1], [1], [1], [1], [1], [1], [2], [2], [2], [2], [2], [1, 2], [1], [3], [3], [1], [1], [1], [1], [2], [2], [2], [2], [2], [1], [1], [4], [2], [1], [2, 3], [1], [1], [1], [1, 2], [1], [0], [4], [1, 2], [2], [1], [1], [1], [1], [2], [1], [1], [1], [2], [2], [1], [2], [2], [2], [4], [1], [2], [2], [2], [2], [1], [1], [1], [1], [1], [1], [1], [2], [2], [2], [4], [1], [2], [2], [1], [1], [2], [2], [1], [1], [3], [1], [1, 2], [2], [1], [1], [1], [1], [1], [1], [2], [1], [1], [2], [2], [1], [2], [1], [2], [1], [2], [3], [3], [2], [1], [2], [1], [1], [1], [1], [1], [2], [1], [1], [3], [1], [1], [1], [1], [2], [2], [2], [2], [1], [2], [1], [1], [2], [2, 3], [1], [1], [1], [2], [1], [1], [2], [2], [4], [1], [2], [1], [2], [3], [1], [2], [2], [1], [3], [1], [1], [2], [2], [2], [3], [3], [2], [1], [2], [1], [1], [2], [2], [1], [1], [2], [3], [1], [1], [1], [3], [1], [2], [1], [2], [1], [1], [2], [1], [1], [1, 2], [1], [1], [1], [2], [1], [2], [1, 2], [1, 2], [2], [1], [2], [3], [1], [2], [2], [2], [1], [2], [1], [3], [1], [1], [1], [2], [1], [2], [3], [1], [2], [2], [1], [1], [2], [1], [1, 2], [1, 2], [1], [1], [1], [1], [1], [1], [2], [2], [1], [1], [3], [1], [1], [2], [1], [2], [1], [1], [2], [2], [1], [1], [1], [2], [2], [1], [1], [2], [1], [2], [1], [1], [1], [2], [2], [1], [1], [2], [2], [1], [2], [1], [2], [2], [2], [1], [1, 2], [4], [1], [2, 3], [1], [3], [2], [1], [1], [1], [2], [2], [1], [3], [1], [1], [1], [1], [1], [2], [1], [2], [1], [1], [1], [3], [1], [1], [1], [1], [2, 3], [2], [2], [1], [1], [2, 3], [2], [2], [2], [2], [2], [2], [1], [2], [1], [1], [2], [1], [1], [1], [3], [1], [3], [1, 2], [1], [2], [1], [1], [2], [1, 2], [1], [1], [1], [1], [2], [1], [1], [1], [1], [1], [2], [3], [1], [2], [1], [2], [1], [1], [2], [1], [2], [1], [1], [3], [1], [1], [2], [1], [1], [1], [2], [1], [2], [2], [1], [1], [1], [2], [2], [2], [1], [1], [1], [1], [2], [1], [1], [1], [1], [1], [1, 2], [1], [1], [2], [2], [2], [2], [1, 2], [1], [1], [1], [5], [2], [2], [1], [2], [1], [1], [1], [2], [2], [2], [1], [1], [3], [2], [1], [1], [1], [2], [1], [2], [1], [2], [1], [4], [1], [1, 2], [1], [1], [1], [2], [3], [2], [1], [2], [2], [2], [1], [1], [2], [1], [2], [1, 2], [2], [2], [2], [1], [1], [1], [3], [1], [1], [2], [4], [1], [1], [1], [3], [1], [1], [1], [3], [2], [1, 2], [1], [1], [3], [1], [1], [2], [2], [2, 3], [1, 2], [2], [1], [1], [1], [1, 2], [2], [1], [1], [2], [1], [2], [1], [1], [1], [2], [3], [1], [1], [1], [2], [2], [3], [2], [2], [2], [2], [2], [2], [3], [1], [2], [1], [1], [1], [2], [2], [2], [2], [1], [2], [1, 2], [3], [1], [2], [2], [1], [2], [2], [2], [1], [1], [1], [2], [1], [1], [1], [1], [2], [1], [1], [1], [1], [2], [2], [1, 2], [2], [2], [1], [1], [2], [1, 2], [2], [2], [1], [1], [1], [1], [1], [2], [2], [2], [2], [2], [1], [2], [3], [1], [1], [1], [2], [1], [1], [2], [1], [1], [2], [1], [3], [1], [2], [1], [2], [1], [2], [1], [1], [3], [1], [1], [2], [1], [1], [1], [3], [1], [2], [1], [1], [2], [1], [1], [1], [1], [2], [1], [1], [2], [2], [1], [2], [1], [2], [3], [1], [2], [2], [2], [1], [1], [1], [1], [3], [2], [2], [3], [1], [1], [2], [1], [2], [2], [2], [1, 2], [1], [2, 3], [2], [1], [2], [1, 2], [1], [1, 2], [2], [2], [3], [1, 2], [1], [1], [1], [2, 3], [1], [1], [1], [2, 3], [2], [1], [1], [2, 3], [1], [1], [1], [2, 3], [3], [2, 3], [2], [2], [1], [1], [1], [2], [3], [1], [1], [1], [1], [2], [2], [1], [1], [1, 2], [1], [2], [1], [2], [2], [1], [2], [1], [2], [1], [2], [3], [1, 2], [2], [2], [1], [2], [2], [2], [1, 2], [1, 2], [1, 2], [1], [1], [2], [1], [2], [1], [1], [3], [2], [1], [2], [1], [2], [1], [2], [1], [2], [2], [4], [1], [1], [1], [2], [2], [3], [1], [3], [2], [1], [3], [2], [1], [2], [1], [2], [1], [1], [1], [2], [1], [2], [2], [2], [1], [3], [2], [2], [2], [1], [2], [2], [1], [1], [2], [1], [2], [2], [1], [1], [1, 2], [2], [2], [1], [1], [2], [1], [3], [1], [3], [1], [1], [2, 3], [1], [1, 2], [2], [3], [2], [1], [2], [3], [1], [1], [1], [1, 2], [1], [2], [1], [2], [2], [1], [3], [1, 2], [2], [2], [1], [1], [2], [3], [2], [1], [1], [1, 2], [1], [1], [1], [2], [2], [4], [1], [1], [1, 2], [1], [3], [2], [1], [3], [1, 2], [2], [2], [1], [1], [1], [1], [2], [1], [2], [1, 2], [2], [2], [2], [1], [2], [1], [1], [2], [2], [2], [2], [2], [1, 2], [2], [2], [1], [5], [2], [2], [2], [1], [1, 2], [1], [2], [1], [1], [1], [2], [2], [1], [2], [3], [1], [3], [1], [2], [3], [2], [1], [2], [1], [2], [2], [2], [1], [1], [1], [1], [1, 2], [4], [2], [1], [1], [2], [2], [2], [1], [1], [1, 2], [2], [2], [2], [1], [1], [2], [1], [1], [1], [2], [2], [1], [3], [1], [1], [2], [3], [1], [2], [2, 3], [2], [1], [1], [1], [2, 3], [2], [1], [1], [1], [1], [1], [1], [2], [2], [1], [1], [1], [1], [1], [1], [2], [1], [2], [2], [2], [1], [1], [2], [2], [1], [3], [2], [3], [1], [2], [4], [1], [1], [1], [2], [2], [3], [1], [2], [2, 3], [1], [1], [2], [3], [1], [3], [1], [2, 3], [2], [2], [1], [2], [2], [3], [1], [2], [4], [1], [1], [3], [3], [1, 2], [2], [2], [2], [3], [2], [1], [1], [1, 2], [1, 2], [1], [1], [1], [1], [1, 2], [3], [1], [2], [1], [1], [1], [2], [2], [1], [2], [1], [2], [2], [2], [1], [1], [3], [2], [2], [2], [1], [2], [1], [3], [2], [2], [1], [2], [2], [1], [2], [1], [1], [3], [2], [2], [1], [2], [1], [1], [1], [2, 3], [1], [1], [1, 2], [1], [2], [1], [1], [1], [2], [2], [2], [1, 2], [1], [2], [1], [3], [1], [1], [1], [1], [1], [2], [1], [2], [1], [3], [1, 2], [1], [2], [1], [3], [1], [1], [1], [1], [2], [1], [1], [2], [1], [2], [2], [1], [3], [1], [2], [2], [2], [1], [4], [2], [3], [2], [2], [3], [1], [2], [1], [1], [1], [2], [2], [3], [2], [1], [2], [2], [4], [1], [1], [2], [1], [2], [1], [1], [2], [1, 2], [4], [1], [1], [2], [1], [4], [1], [2], [1], [1], [2], [3], [3], [1], [3], [1], [1, 2], [1], [1], [1], [2], [3], [2], [1], [2], [2], [2], [1, 2], [3], [1, 2], [1], [3], [2, 3], [2], [2], [2], [1], [2], [3], [3], [2], [2], [1], [1], [3], [1], [2], [3], [1], [1], [2], [3], [2], [1], [2], [1], [2], [1], [1], [3], [4], [2], [2], [2], [1], [1, 2], [3], [2], [2], [1], [1], [2, 3], [1], [1, 2], [1], [2, 3], [2], [1], [2, 3], [2], [2], [3], [1, 2], [1], [1], [3], [3], [1], [1], [1], [2], [1], [3], [2], [1], [2], [3], [2], [1], [2], [1], [2], [1], [1], [1], [2], [2], [1], [2], [1], [2], [1], [2], [1], [1, 2], [2], [1, 2], [3], [1], [2], [1], [1], [2], [2], [1], [2], [1], [1], [1], [2, 3], [1], [3, 4], [1], [1], [2], [1], [2, 3], [2], [2], [1], [1, 2], [3], [3], [2], [1], [1], [1], [3], [2], [1], [2], [2], [1, 2], [1], [2], [2], [1], [1], [1], [1], [1], [1], [1], [1], [1], [2], [2], [3], [3], [1], [2], [2], [1], [3], [4], [1], [2], [1], [2], [3], [1], [1], [1], [3, 4], [2], [1], [4], [2], [3], [2], [2, 3], [1], [3], [1], [1], [2], [2], [1], [2], [1], [2], [1], [2], [3], [1], [3], [1], [2], [4], [1], [2], [2], [4], [1], [2], [1], [2], [1], [1], [2], [2], [1], [1, 2], [2], [1], [2], [1], [1], [1], [1, 2], [2], [1], [2], [2], [2], [2], [1], [2], [1], [1], [2], [2], [2], [1], [1], [1], [1], [1], [2], [1], [1], [1], [2], [1], [2], [1], [2], [1], [2], [2], [2], [1], [2], [1], [2], [2], [3], [2], [2], [2], [1], [1], [2], [1], [1], [2], [1], [1], [2], [2], [1], [1], [2], [1], [2], [1], [2], [1], [1], [2], [2], [2], [1], [2], [1], [1], [2], [2], [2], [2], [2], [1], [4], [2], [2], [1], [1], [2], [1], [2], [1], [1], [2], [1], [3], [1], [1], [1], [3], [2], [2], [1], [2], [1], [2], [1], [1], [2], [2], [2], [3], [2], [1], [2], [2], [3], [3], [3], [3], [1], [2], [2], [1], [1], [2], [3], [2], [4], [2], [1], [2], [1], [2], [3], [1], [2], [1], [1], [2], [2], [1], [3], [1], [3], [2], [2], [1], [2], [2], [2], [2], [3], [2], [2], [2], [1], [2], [2], [2], [3], [1], [1], [3], [1], [1], [1], [1], [2], [4], [3], [1], [2], [2], [2], [2], [1], [1], [2], [3], [2], [1, 2], [2], [3], [2], [2], [1], [2], [1, 2], [1, 2], [3, 4], [1, 2], [2], [2], [1], [1], [1], [2], [1], [1], [1], [3], [2], [4], [1], [3], [1], [2], [2], [2], [2], [2], [1], [1], [1], [2], [1], [2], [1], [2], [1], [2], [1], [2], [1], [1], [3], [1], [2], [3], [2], [2], [3], [1], [2], [1], [1], [1], [2], [2], [2], [2], [2], [1], [2], [2], [3], [3], [2], [2], [4], [1], [2], [1], [3], [1], [2], [2], [1], [2], [2], [2], [4], [1], [1], [4], [2], [2], [2], [2], [2], [1], [3], [1], [3], [1], [1], [2], [1, 2], [1], [1], [1], [1], [1], [2], [2], [3], [2], [2], [2], [1], [2], [1], [1], [3], [1], [3], [2], [2], [1], [2], [2], [2], [1], [1], [4], [3], [3], [4], [2], [1], [2], [1], [2], [2], [2], [1], [1], [3], [3], [1], [1], [2], [2], [2], [1], [2], [1], [2], [1], [3], [2], [1], [1], [1], [2], [3], [3], [3], [2], [1], [3], [1], [1], [2], [4], [2], [1], [2], [1], [2], [2], [1], [2], [1], [4], [1], [1], [1], [2], [2], [4], [1], [3], [1], [2], [1], [2], [1], [2], [1], [3], [2], [1], [4], [2], [3], [2], [2], [3], [3], [2], [2], [1], [4], [2], [4], [3], [2], [2], [4], [2], [2, 3], [4], [2], [1], [4], [3], [4], [2], [2], [1], [2], [1], [3], [1], [1], [1], [1], [1], [1], [2], [1], [1], [3], [2], [3], [1], [1], [1], [3], [2], [1], [1], [1], [1], [1], [2], [2], [2], [1, 2], [1], [1], [1, 2], [1], [1], [1], [1], [1], [2], [2], [2], [2], [2], [1], [1], [2], [1], [1], [2], [1], [3], [1], [2], [2], [1], [1], [2], [2], [2], [1], [1], [2], [1], [2], [1], [1], [2], [1], [1], [3], [2], [2], [3], [1], [1], [1], [2], [2], [3], [2], [2], [1], [2], [1], [1], [2], [1], [1], [1], [1], [1], [2], [2], [2], [1], [2], [2], [2], [2], [2], [2], [2], [2], [1], [2], [3], [3], [2], [3], [1], [1], [2], [2], [2], [2], [1], [3], [1], [1], [1], [1], [1], [2], [3], [2], [2], [2], [2], [2], [1], [2], [2, 3], [3], [1], [2], [3], [4], [1], [2], [2], [2], [2], [2], [1], [2], [2], [2], [2], [2], [3], [1], [2], [2], [2], [1], [2], [2], [2], [1], [2], [2], [1], [2], [4], [2], [2], [1], [2], [1], [3], [1], [3], [3], [2], [2], [2], [3], [2], [1], [3], [2], [3], [2], [1], [2], [2], [2], [1], [2], [2], [1], [1], [2], [2], [1], [2], [1], [2], [2], [2], [1], [1], [3], [2], [1], [1], [1], [1, 2], [2], [1], [1], [2], [2], [1], [2], [1], [3], [1], [3], [2], [2], [2], [1], [2], [1], [1], [2], [2], [3], [2, 3], [3], [1], [3], [3], [2], [2], [1], [1], [2], [2], [4], [2], [2], [2], [2], [2], [2], [2], [1], [3], [2], [2], [3], [3], [1], [3], [1], [1], [2], [1], [2], [1], [1], [2], [2], [1], [2], [2], [2], [1], [2], [3], [3], [2], [1], [1], [3], [1], [3], [1, 2], [3], [3], [2], [2], [2], [2], [2], [1], [2], [1], [3], [1], [2], [1], [2], [2], [2], [3], [2], [1], [2], [2], [1], [2], [2], [2], [1], [2], [2], [4], [3], [3], [1], [1], [4], [2], [3], [3], [2], [3], [2, 3], [1], [4], [1, 2], [2], [2, 3], [2], [1, 2], [2, 3], [3], [1], [1], [2], [2], [2], [2], [2, 3], [2], [2], [3], [2], [2], [4], [2], [1], [2, 3], [2], [1], [2], [1], [1], [2], [1], [1], [1], [1], [3], [1], [2], [2], [2], [2], [1, 2], [2], [2], [3], [2], [1], [2], [1], [2], [2], [3], [1], [1], [2], [2], [1], [4], [2, 3], [2], [2], [1], [2], [2], [1], [2], [2], [1], [2], [1], [3], [3], [2, 3], [2], [2], [2], [3], [1], [1], [3], [2], [2], [1, 2], [1], [2], [1], [3], [2], [3], [1], [1], [2], [2], [3], [2], [3], [1], [2], [2], [2], [2], [1], [2], [2], [1], [2], [2], [2], [2], [2], [4], [1], [1], [1], [3], [2], [2], [3], [2], [2], [2], [1], [2], [2], [1], [3], [1], [1], [1], [1], [2], [1], [2], [2], [2], [2], [1], [3], [3], [2], [2], [1], [2], [2], [2], [1], [3], [1], [2], [2, 3], [1], [2], [1], [2], [2], [1], [1], [2], [1], [1], [1], [2], [1], [2], [3], [2], [2], [1], [2], [2], [3], [2], [2], [2], [1], [2], [2], [2], [2], [1], [2], [2], [2], [2], [2], [1], [3], [2], [3], [1], [2], [2], [2], [3], [2, 3], [2], [2], [1], [3], [1], [1], [1], [1], [2], [2], [1], [1], [2], [1], [2], [3], [2], [2], [2], [1], [2], [1], [1], [1], [1], [2], [1], [2], [1], [1], [2], [2], [1], [1], [2], [2], [2], [4], [2], [2], [1], [2], [3], [2], [3], [3], [2], [1], [3], [2], [3], [1], [3], [2], [1], [2], [1], [3], [4], [1], [3], [3], [2], [2], [2], [2], [2], [2], [4], [1], [2], [2], [2], [1], [2], [2], [2], [1], [1], [1], [2], [3], [2], [1], [1], [2], [2], [1], [4], [1], [1], [1], [3], [2], [1], [2], [1], [2], [1], [2], [1], [4], [1], [3], [2], [2], [1], [1], [1], [3], [3], [2], [2], [2], [1], [1], [2], [1], [1], [2], [1], [2], [2], [2], [2], [1], [2], [1], [2], [2], [2], [2], [1], [2], [2], [2], [2], [2], [2, 3], [2], [1], [3], [2], [1], [2], [1], [1], [2], [2], [2], [1], [2], [2], [2], [3], [1], [2], [2], [2], [2], [2], [2], [4], [3], [1], [1], [2], [2], [1], [1], [2], [2], [1, 2], [1], [1], [1, 2], [4], [2], [2], [1], [1], [2], [3], [3], [2, 3], [3], [1], [2, 3], [2], [1], [1], [1, 2], [2], [1], [2], [2], [2], [1], [1, 2], [3], [2], [2], [3], [1], [1], [2], [1], [1], [2], [2], [1], [2], [2], [3], [2], [4], [2], [2], [2], [4], [2], [4], [1], [3], [4], [2], [1, 2], [2], [1], [2], [1, 2], [2], [1], [2], [2], [1], [2], [2], [2], [2], [2], [2], [3], [2], [2], [3], [2], [4], [1, 2], [1], [2], [2], [2], [1], [2], [3], [2], [1], [2], [1], [2], [2], [2], [1, 2], [2], [1, 2], [3], [0], [4], [1], [3], [2], [2], [1], [2], [1], [2], [1], [1], [2], [2], [1], [3], [1], [2, 3], [1], [1, 2], [3], [2], [1, 2], [1], [2], [2], [2], [3], [1], [2], [3], [1], [1], [2], [2], [1], [1], [1, 2], [2], [2], [1], [2], [1], [2], [2], [2], [3], [4], [2], [2], [1], [1], [3], [2], [1, 2], [2], [2], [2], [3], [2], [2], [3], [2], [3], [1], [3], [2], [1], [1], [2], [2], [4], [3], [2], [2], [1], [2], [1], [2], [1], [3], [2], [2], [2], [3], [1, 2], [2], [3], [2], [2], [1], [1], [1], [2], [3], [3], [3], [2], [3], [2], [3], [1], [1], [1], [1], [2], [3], [1], [2], [3], [2], [2], [1], [2], [3], [1, 2], [3], [2], [2], [3], [1], [2], [2], [2], [3], [2], [2], [3], [2], [2], [1], [2], [1], [2], [2], [2], [2], [2], [3], [1], [1], [2], [2], [1], [2], [1], [1], [2], [1], [1], [2], [2], [2], [4], [2], [1], [1], [1], [1], [2], [2], [2], [2], [2], [2], [2], [2], [1], [2], [1], [2], [1], [2], [2], [1], [1], [1], [1], [1], [1], [2], [1], [1], [1], [2], [3], [2], [2], [1], [1], [1], [1], [2], [2], [2], [2], [1], [1], [1], [2], [2], [2], [2], [2], [1], [2], [2], [2], [1], [2], [2], [2, 3], [2], [1], [2], [1], [2], [2], [1], [2], [2], [2], [2], [3], [1], [3], [1], [1], [1], [2], [1], [1], [1], [2], [1], [3], [1], [3], [3], [3], [2], [3], [3], [2], [2], [2], [2], [2], [1], [2], [4], [2], [1], [2], [1], [1], [2], [1], [1], [2], [1], [3], [3], [3], [2], [2], [2], [3], [1], [2], [2], [2], [2], [3], [1], [1], [2], [1], [2], [1], [1], [2], [4], [2], [1], [3], [2], [2], [3], [3], [1], [2], [2], [1], [1], [1], [1], [1], [2, 3], [1], [2, 3], [2], [2], [2], [2], [2], [2], [2], [2, 3], [2], [3], [1], [1], [1], [3], [1], [1], [3], [2], [2], [4], [2], [2], [1], [2], [1], [2], [3], [1], [2], [2], [2], [2], [1], [2], [1], [1], [2], [2], [2], [2], [2], [2], [2], [1], [1, 2], [2], [3], [1], [3], [1], [1], [2], [2], [2], [2], [2], [1], [1], [1], [2], [2], [2], [1], [2], [1], [2], [4], [2], [1], [2], [3], [1], [1], [2], [1], [1], [1], [1], [2], [2], [2], [2], [2], [3], [2], [3], [2], [3], [2], [2], [3], [2], [2], [2], [1], [4], [2], [2], [2], [2], [1], [2], [2], [2], [1], [1], [1], [3], [2], [3], [2], [1], [1], [1], [2], [2], [2], [3], [5], [2], [2], [3], [2], [2], [4], [1], [2], [2], [3], [2], [1, 2], [1], [2], [1], [1, 2], [1], [2], [1], [2], [1], [1], [2], [2], [2], [3], [1, 2], [2], [2], [1], [2], [3], [2], [1], [4], [2], [2], [1], [2], [2], [1], [2], [2], [1], [3]]\n",
      "corpus length: 19972\n",
      "total words: 3160\n",
      "nb sequences: 19964\n",
      "Vectorization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "### https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "''' Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "from Sonnet_Set import Sonnet_Set\n",
    "from Sonnet_Set import Sequence_Type\n",
    "from Sonnet_Set import Element_Type\n",
    "\n",
    "sonnet_set = Sonnet_Set(\"data/shakespeare.txt\")\n",
    "sonnets = open(\"data/shakespeare.txt\")\n",
    "sonnet_sequences = sonnet_set.get_sequences(sequence_type=Sequence_Type.SONNET, element_type=Element_Type.WORD)\n",
    "\n",
    "text =[word for sonnet in sonnet_sequences for word in sonnet]\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "words = sorted(list(set(text)))\n",
    "print('total words:', len(words))\n",
    "word_indices = dict((w, i) for i, w in enumerate(words))\n",
    "indices_word = dict((i, w) for i, w in enumerate(words))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 8\n",
    "step = 1\n",
    "sentences = []\n",
    "next_words = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_words.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(words)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(words)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, word in enumerate(sentence):\n",
    "        x[i, t, word_indices[word]] = 1\n",
    "    y[i, word_indices[next_words[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(words))))\n",
    "model.add(Dense(len(words)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "19964/19964 [==============================] - 46s 2ms/step - loss: 1.2034\n",
      "Epoch 2/60\n",
      "19964/19964 [==============================] - 46s 2ms/step - loss: 1.1856\n",
      "Epoch 3/60\n",
      "19964/19964 [==============================] - 726s 36ms/step - loss: 1.2035\n",
      "Epoch 4/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1853\n",
      "Epoch 5/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1890\n",
      "Epoch 6/60\n",
      "19964/19964 [==============================] - 47s 2ms/step - loss: 1.1756\n",
      "Epoch 7/60\n",
      "19964/19964 [==============================] - 47s 2ms/step - loss: 1.1721\n",
      "Epoch 8/60\n",
      "19964/19964 [==============================] - 47s 2ms/step - loss: 1.1809\n",
      "Epoch 9/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1699\n",
      "Epoch 10/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.1654\n",
      "Epoch 11/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1501\n",
      "Epoch 12/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1647\n",
      "Epoch 13/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.1498\n",
      "Epoch 14/60\n",
      "19964/19964 [==============================] - 47s 2ms/step - loss: 1.1480\n",
      "Epoch 15/60\n",
      "19964/19964 [==============================] - 46s 2ms/step - loss: 1.1454\n",
      "Epoch 16/60\n",
      "19964/19964 [==============================] - 47s 2ms/step - loss: 1.1456\n",
      "Epoch 17/60\n",
      "19964/19964 [==============================] - 50s 3ms/step - loss: 1.1333\n",
      "Epoch 18/60\n",
      "19964/19964 [==============================] - 46s 2ms/step - loss: 1.1333\n",
      "Epoch 19/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1403\n",
      "Epoch 20/60\n",
      "19964/19964 [==============================] - 47s 2ms/step - loss: 1.1284\n",
      "Epoch 21/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1305\n",
      "Epoch 22/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1247\n",
      "Epoch 23/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1256\n",
      "Epoch 24/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.1230\n",
      "Epoch 25/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1220\n",
      "Epoch 26/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.1226\n",
      "Epoch 27/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1094\n",
      "Epoch 28/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1104\n",
      "Epoch 29/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1183\n",
      "Epoch 30/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.1145\n",
      "Epoch 31/60\n",
      "19964/19964 [==============================] - 59s 3ms/step - loss: 1.1157\n",
      "Epoch 32/60\n",
      "19964/19964 [==============================] - 69s 3ms/step - loss: 1.1093\n",
      "Epoch 33/60\n",
      "19964/19964 [==============================] - 77s 4ms/step - loss: 1.1070\n",
      "Epoch 34/60\n",
      "19964/19964 [==============================] - 78s 4ms/step - loss: 1.1171\n",
      "Epoch 35/60\n",
      "19964/19964 [==============================] - 78s 4ms/step - loss: 1.0993\n",
      "Epoch 36/60\n",
      "19964/19964 [==============================] - 76s 4ms/step - loss: 1.1024\n",
      "Epoch 37/60\n",
      "19964/19964 [==============================] - 78s 4ms/step - loss: 1.1011\n",
      "Epoch 38/60\n",
      "19964/19964 [==============================] - 76s 4ms/step - loss: 1.0966\n",
      "Epoch 39/60\n",
      "19964/19964 [==============================] - 77s 4ms/step - loss: 1.0918\n",
      "Epoch 40/60\n",
      "19964/19964 [==============================] - 64s 3ms/step - loss: 1.1079\n",
      "Epoch 41/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.0956\n",
      "Epoch 42/60\n",
      "19964/19964 [==============================] - 51s 3ms/step - loss: 1.0852\n",
      "Epoch 43/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.0957\n",
      "Epoch 44/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.0836\n",
      "Epoch 45/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.0853\n",
      "Epoch 46/60\n",
      "19964/19964 [==============================] - 50s 3ms/step - loss: 1.0859\n",
      "Epoch 47/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.0769\n",
      "Epoch 48/60\n",
      "19964/19964 [==============================] - 50s 3ms/step - loss: 1.0830\n",
      "Epoch 49/60\n",
      "19964/19964 [==============================] - 53s 3ms/step - loss: 1.0796\n",
      "Epoch 50/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.0802\n",
      "Epoch 51/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.0762\n",
      "Epoch 52/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.0886\n",
      "Epoch 53/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.0778\n",
      "Epoch 54/60\n",
      "19964/19964 [==============================] - 48s 2ms/step - loss: 1.0865\n",
      "Epoch 55/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.0708\n",
      "Epoch 56/60\n",
      "19964/19964 [==============================] - 50s 2ms/step - loss: 1.0886\n",
      "Epoch 57/60\n",
      "19964/19964 [==============================] - 47s 2ms/step - loss: 1.0706\n",
      "Epoch 58/60\n",
      "19964/19964 [==============================] - 49s 2ms/step - loss: 1.0649\n",
      "Epoch 59/60\n",
      "19964/19964 [==============================] - 52s 3ms/step - loss: 1.0665\n",
      "Epoch 60/60\n",
      "19964/19964 [==============================] - 51s 3ms/step - loss: 1.0736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ec465ec18>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "         batch_size=128,\n",
    "         epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sonnets = len(sonnet_sequences)\n",
    "num_words = len(words)\n",
    "        \n",
    "\n",
    "# Calculate sonnet context vectors\n",
    "\n",
    "sonnet_contexts = np.zeros((num_sonnets, num_words))\n",
    "\n",
    "for sonnet_index, sonnet in enumerate(sonnet_sequences):\n",
    "    for word in sonnet:\n",
    "        sonnet_contexts[sonnet_index, word] += 1\n",
    "\n",
    "row_sums = sonnet_contexts.sum(axis=1)\n",
    "sonnet_contexts = sonnet_contexts / row_sums[:, np.newaxis]\n",
    "\n",
    "column_means = sonnet_contexts.mean(axis=0)\n",
    "column_sds = sonnet_contexts.std(axis=0)\n",
    "\n",
    "sonnet_contexts = sonnet_contexts - column_means[np.newaxis, :]\n",
    "sonnet_contexts = sonnet_contexts / column_sds[np.newaxis, :]\n",
    "\n",
    "def calculate_word_sequence_context(word_sequence):\n",
    "    \n",
    "    word_sequence_context = np.zeros((num_words,))\n",
    "    \n",
    "    for word in word_sequence:\n",
    "        word_sequence_context[word] += 1\n",
    "    \n",
    "    word_sequence_context = word_sequence_context / sum(word_sequence_context)\n",
    "    \n",
    "    word_sequence_context = word_sequence_context - column_means\n",
    "    word_sequence_context = word_sequence_context / column_sds\n",
    "    \n",
    "    return word_sequence_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- diversity: 0.25\n",
      "----- Generating with seed -----\n",
      "Thy sweet virtue answer not thy show:\n",
      ":\n",
      ":\n",
      ".\n",
      "----- End seed -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And they that have fair i at set more all,\n",
      "And make my love before my verse in sweet,\n",
      "Crooked join reeks flourish attainted thought fall,\n",
      "Situation return iniquity meet:\n",
      "Heaven distance spring mend plight jacks nimble purge,\n",
      "Foison heavy revenues fled actor heaven,\n",
      "Cheeks bar foe scarlet thinking gazed adonis urge,\n",
      "Red moods onset fester we if sometimes even:\n",
      "Impanelled sin hear stops quill t' scanted wrought,\n",
      "Cheater every petty came paws onward lover,\n",
      "Pry overthrow gravity who's rearward sought,\n",
      "Curious lest plods fuel shade manners light cover:\n",
      "  Off breasts besiege contracted wise then o'er,\n",
      "  Love's proving snow lover's shines delves pass shore.\n",
      "----- diversity: 0.75\n",
      "----- Generating with seed -----\n",
      "Thy sweet virtue answer not thy show:\n",
      ":\n",
      ":\n",
      ".\n",
      "----- End seed -----\n",
      "And they that have a i here find thy growing,\n",
      "Quite if it it my with part but be removed,\n",
      "Life sober teachest admire furrows knowing,\n",
      "Decree tattered asked justify special beloved:\n",
      "Forget theirs use glance alas stormy own,\n",
      "Couplement whatsoever art's commanded best,\n",
      "Eve's forget sometimes sees graced despair shown,\n",
      "Tomb before accidents falls tied elder west:\n",
      "Loving offences crime stirred heart's struck pitying yore,\n",
      "Region prisoner thralled mightst ne'er hot unfathered,\n",
      "Boast aught given dressings maladies awards more,\n",
      "Brow humble begins heart's unkind play'st gathered:\n",
      "  Pursuit yours sorrow instinct fear impeached so,\n",
      "  Falsely mixed prevent'st politic tillage owe.\n",
      "----- diversity: 1\n",
      "----- Generating with seed -----\n",
      "Thy sweet virtue answer not thy show:\n",
      ":\n",
      ":\n",
      ".\n",
      "----- End seed -----\n",
      "If they that tears this bounty before me,\n",
      "Which it sunk winters my dead clouds this mind,\n",
      "Qualify marble dig was touched ruinate idolatry,\n",
      "Stout sky mow restore delighted pluck mayst kind:\n",
      "Respects bail fearful sweetness wail grow several comment,\n",
      "Oblivion depart blush churl parallels forbid,\n",
      "Straight roof shine usest offenders invocate moment,\n",
      "Respect unthrift expressing undivided hid:\n",
      "Sickness thinks speaking worthy league hast fee,\n",
      "Likeness palate rare badges brood word deem,\n",
      "Warm skill alt'ring all-eating embassy decree,\n",
      "Love's grind already creatures bed-vow seem:\n",
      "  Impression victories friend store neither yore,\n",
      "  Torment kiss sufferance suffer hems proof more.\n",
      "----- diversity: 1.5\n",
      "----- Generating with seed -----\n",
      "Thy sweet virtue answer not thy show:\n",
      ":\n",
      ":\n",
      ".\n",
      "----- End seed -----\n",
      "Was they that have rude wand'ring dearths shows o'er,\n",
      "Devised woman saw fresh semblance instant fixed,\n",
      "Salving birds effectually bare clay before,\n",
      "Hasten gulls dearest concord keep'st pleased intermixed:\n",
      "Divining course numbers injuries arrest,\n",
      "Make siege perceiv'st perspective spoils impair dye,\n",
      "Dote affable brief eyes ruining interest,\n",
      "Wink fortune's commit taught falsely spacious wantonly:\n",
      "Foiled answer doom tempteth others skill passion,\n",
      "Wanton alchemy subject posterity grind,\n",
      "Muses suff'ring swift-footed sake mercy fashion,\n",
      "Strong laid prepare unwooed summers kingly bind:\n",
      "  Verse picture figure uphold bosom's frown,\n",
      "  Bett'ring revenues travels decease down.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Generating with some sensicalness\n",
    "\n",
    "random_sonnet_index = np.random.choice(range(len(sonnet_sequences)))\n",
    "random_sonnet = sonnet_sequences[random_sonnet_index]\n",
    "\n",
    "num_sonnets_to_compare_to = 20\n",
    "context_weight = 1.0\n",
    "\n",
    "# Pick the end of a line - this should serve as a decent seed for starting a new poem\n",
    "sentence = random_sonnet[-maxlen - 1:-1]\n",
    "\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "for diversity in [0.25, 0.75, 1, 1.5]:\n",
    "    print('----- diversity:', diversity)\n",
    "    \n",
    "    print(\"----- Generating with seed -----\")\n",
    "    sonnet_set.print_sonnet(sentence, sequence_type=Sequence_Type.SONNET, element_type=Element_Type.WORD)\n",
    "    print('----- End seed -----')\n",
    "    \n",
    "    current_phrase_window = sentence[:]\n",
    "    generated_sonnet = []\n",
    "    current_sonnet_line = 0\n",
    "    num_syllables_this_line = 0\n",
    "    previous_rhymable_words = [None, None]\n",
    "    \n",
    "    rhyming_words_vector = [1 if i in sonnet_set._rhyme_dictionary.keys() else 0 for i in range(len(words))]\n",
    "    not_new_line_vector = [1 if i < sonnet_set._word_dictionary[Sonnet_Set.NEW_LINE_CHARACTER]\n",
    "                           else 0 for i in range(len(words))]\n",
    "\n",
    "    while current_sonnet_line < 14:\n",
    "        \n",
    "        x_pred = np.zeros((1, maxlen, len(words)))\n",
    "        \n",
    "        for t, word in enumerate(current_phrase_window):\n",
    "            x_pred[0, t, word_indices[word]] = 1.\n",
    "        \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        \n",
    "        if current_sonnet_line > 1:\n",
    "            word_sequence_context = calculate_word_sequence_context(generated_sonnet)\n",
    "            sonnet_similarities = np.zeros((num_sonnets,))\n",
    "            for sonnet_index, sonnet in enumerate(sonnet_sequences):\n",
    "                sonnet_similarity = np.matmul(word_sequence_context.T, sonnet_contexts[sonnet_index].T)\n",
    "                sonnet_similarities[sonnet_index] = sonnet_similarity\n",
    "            most_similar_sonnets = sonnet_similarities.argsort()[-num_sonnets_to_compare_to:][::-1]\n",
    "            least_similar_sonnets = sonnet_similarities.argsort()[0:num_sonnets_to_compare_to]\n",
    "            \n",
    "            context_weights = np.array((num_words,))\n",
    "            \n",
    "            for sonnet_index in most_similar_sonnets:\n",
    "                context_weights = context_weights + sonnet_contexts[sonnet_index]\n",
    "            \n",
    "            for sonnet_index in least_similar_sonnets:\n",
    "                context_weights = context_weights - sonnet_contexts[sonnet_index]\n",
    "            \n",
    "            context_weights = (context_weights - context_weights.min()) / context_weights.max()\n",
    "            \n",
    "            context_weights = context_weights / context_weights.sum()\n",
    "            \n",
    "            preds = (1 - context_weight) * preds + (context_weight * context_weights)\n",
    "        \n",
    "        # If we're on the last syllable, this must be a rhymable word\n",
    "        if num_syllables_this_line >= 9:\n",
    "            if current_sonnet_line in [0, 1, 4, 5, 8, 9, 12]:\n",
    "                preds = np.multiply(preds, rhyming_words_vector)\n",
    "                next_word = sample(preds, diversity)\n",
    "                if current_sonnet_line in [0, 4, 8, 12]:\n",
    "                    previous_rhymable_words[0] = next_word\n",
    "                else:\n",
    "                    previous_rhymable_words[1] = next_word\n",
    "            \n",
    "                #print(\"Next rhymable word is '%s'\" % sonnet_set._word_list[next_word])\n",
    "            elif current_sonnet_line in [2, 3, 6, 7, 10, 11, 13]:\n",
    "                \n",
    "                if current_sonnet_line in [2, 6, 10, 13]:\n",
    "                    previous_rhymable_word = previous_rhymable_words[0]\n",
    "                else:\n",
    "                    previous_rhymable_word = previous_rhymable_words[1]\n",
    "                    \n",
    "                rhyme_partners = sonnet_set._rhyme_pairs[sonnet_set._rhyme_dictionary[previous_rhymable_word]]\n",
    "                rhyme_partner_vector = [1 if i in rhyme_partners else 0 for i in range(len(preds))]\n",
    "                rhyme_partner_vector[previous_rhymable_word] = 0\n",
    "                preds = np.multiply(preds, rhyme_partner_vector)\n",
    "                next_word = sample(preds, diversity)\n",
    "                previous_rhymable_word = None\n",
    "            \n",
    "                #print(\"Next rhyming word is '%s'\" % sonnet_set._word_list[next_word])\n",
    "            current_phrase_window = current_phrase_window[1:]+[next_word]\n",
    "            generated_sonnet.append(next_word)\n",
    "            num_syllables_this_line += sonnet_set._syllable_list_num[next_word][0]\n",
    "            next_word = sonnet_set._word_dictionary[Sonnet_Set.NEW_LINE_CHARACTER]\n",
    "            current_sonnet_line += 1\n",
    "            num_syllables_this_line = 0\n",
    "        else:\n",
    "            preds = np.multiply(preds, not_new_line_vector)\n",
    "            next_word = sample(preds, diversity)\n",
    "            num_syllables_this_line += sonnet_set._syllable_list_num[next_word][0]\n",
    "            \n",
    "            #print(\"Next word is '%s'\" % sonnet_set._word_list[next_word])\n",
    "            \n",
    "        current_phrase_window = current_phrase_window[1:]+[next_word]\n",
    "        generated_sonnet.append(next_word)\n",
    "        \n",
    "    #print(generated_sonnet)\n",
    "\n",
    "    sonnet_set.print_sonnet(generated_sonnet, sequence_type=Sequence_Type.SONNET, element_type=Element_Type.WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
